{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "279d59d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>married</th>\n",
       "      <th>earn96</th>\n",
       "      <th>unem96</th>\n",
       "      <th>earn98</th>\n",
       "      <th>unem98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.617924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  age  educ  black  hisp  married  earn96  unem96    earn98  unem98\n",
       "0      0   37    11      1     0        1     0.0       1  1.617924       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat as st\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 2T\\[MT08-MT13] Microeconometría II\\Clases\\Stata\\jobtraining.dta\"\n",
    "\n",
    "df, meta = st.read_dta(path)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f91e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation  (IPW ATE)\n",
      "\n",
      "Estimator      : inverse-probability weights\n",
      "Outcome model  : weighted mean\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "      earn98 |  Coefficient   Std. Err.         z    P>|z|        [95% Conf. Interval]\n",
      "------------------------------------------------------------------------------\n",
      "         ATE |     1.046882    0.494240     2.118    0.034     (0.078171, 2.015593)\n",
      "    POmean 0 |     9.174996    0.267456    34.305    0.000     (8.650783, 9.699210)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# ---------- Utilidades ----------\n",
    "def _bootstrap(fn, data, n_boot=1000, random_state=123):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    idx = np.arange(len(data))\n",
    "    stats_boot = []\n",
    "    for _ in range(n_boot):\n",
    "        samp = data.iloc[rng.choice(idx, size=len(idx), replace=True)]\n",
    "        stats_boot.append(fn(samp))\n",
    "    return np.array(stats_boot)\n",
    "\n",
    "def _ipw_stats(df, p_col=\"p_hat\", y_col=\"earn98\", d_col=\"train\"):\n",
    "    p = df[p_col].to_numpy()\n",
    "    y = df[y_col].to_numpy()\n",
    "    d = df[d_col].to_numpy()\n",
    "\n",
    "    # Pesos estabilizados y normalizados\n",
    "    w1 = d / p\n",
    "    w0 = (1 - d) / (1 - p)\n",
    "    w1 /= w1.sum()\n",
    "    w0 /= w0.sum()\n",
    "\n",
    "    mu1 = np.sum(w1 * y)\n",
    "    mu0 = np.sum(w0 * y)\n",
    "    ate = mu1 - mu0\n",
    "    return pd.Series({\"mu1\": mu1, \"mu0\": mu0, \"ate\": ate})\n",
    "\n",
    "# ---------- Estimación principal ----------\n",
    "def teffects_ipw(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=[\"age\", \"educ\", \"earn96\"],\n",
    "    noconstant=True,\n",
    "    clip=(1e-6, 1 - 1e-6),\n",
    "    n_boot=2000,\n",
    "    random_state=42\n",
    "):\n",
    "    # 1) Tratamiento ~ X (logit)\n",
    "    X = df[x].copy()\n",
    "    if not noconstant:\n",
    "        X = sm.add_constant(X, has_constant=\"add\")\n",
    "\n",
    "    model = sm.Logit(df[d], X)\n",
    "    res = model.fit(disp=False)\n",
    "\n",
    "    # 2) Propensión y clipping\n",
    "    p_hat = res.predict(X)\n",
    "    if clip is not None:\n",
    "        low, high = clip\n",
    "        p_hat = np.clip(p_hat, low, high)\n",
    "\n",
    "    tmp = df[[y, d]].copy()\n",
    "    tmp[\"p_hat\"] = p_hat\n",
    "\n",
    "    # 3) Estadísticos puntuales\n",
    "    point = _ipw_stats(tmp, p_col=\"p_hat\", y_col=y, d_col=d)\n",
    "\n",
    "    # 4) Bootstrap (no-paramétrico) para SE, z, p, CI\n",
    "    def stat_fn(sample_df):\n",
    "        # Re-estimar p(X) dentro del bootstrap (como hace Stata con \"robust\"?)\n",
    "        Xb = sample_df[x].copy()\n",
    "        if not noconstant:\n",
    "            Xb = sm.add_constant(Xb, has_constant=\"add\")\n",
    "        m_b = sm.Logit(sample_df[d], Xb).fit(disp=False)\n",
    "        p_b = np.clip(m_b.predict(Xb), clip[0], clip[1]) if clip else m_b.predict(Xb)\n",
    "\n",
    "        df_b = sample_df[[y, d]].copy()\n",
    "        df_b[\"p_hat\"] = p_b\n",
    "        s = _ipw_stats(df_b, p_col=\"p_hat\", y_col=y, d_col=d)\n",
    "        # Devolvemos mu0 y ate (para emular POmean train=0 y ATE)\n",
    "        return np.array([s[\"mu0\"], s[\"ate\"]])\n",
    "\n",
    "    boots = _bootstrap(stat_fn, df, n_boot=n_boot, random_state=random_state)\n",
    "    mu0_boot = boots[:, 0]\n",
    "    ate_boot = boots[:, 1]\n",
    "\n",
    "    # SE y z para ATE\n",
    "    ate_se = ate_boot.std(ddof=1)\n",
    "    ate_z = point[\"ate\"] / ate_se if ate_se > 0 else np.nan\n",
    "    ate_p = 2 * (1 - stats.norm.cdf(abs(ate_z)))\n",
    "    ate_ci = (point[\"ate\"] - 1.96 * ate_se, point[\"ate\"] + 1.96 * ate_se)\n",
    "\n",
    "    # SE y z para POmean (train=0)\n",
    "    mu0_se = mu0_boot.std(ddof=1)\n",
    "    mu0_z = point[\"mu0\"] / mu0_se if mu0_se > 0 else np.nan\n",
    "    mu0_p = 2 * (1 - stats.norm.cdf(abs(mu0_z)))\n",
    "    mu0_ci = (point[\"mu0\"] - 1.96 * mu0_se, point[\"mu0\"] + 1.96 * mu0_se)\n",
    "\n",
    "    out = {\n",
    "        \"ATE\": {\n",
    "            \"coef\": float(point[\"ate\"]),\n",
    "            \"se\": float(ate_se),\n",
    "            \"z\": float(ate_z),\n",
    "            \"p\": float(ate_p),\n",
    "            \"ci95\": ate_ci\n",
    "        },\n",
    "        \"POmean_train_0\": {\n",
    "            \"coef\": float(point[\"mu0\"]),\n",
    "            \"se\": float(mu0_se),\n",
    "            \"z\": float(mu0_z),\n",
    "            \"p\": float(mu0_p),\n",
    "            \"ci95\": mu0_ci\n",
    "        },\n",
    "        \"treatment_model\": {\n",
    "            \"params\": res.params.to_dict(),\n",
    "            \"converged\": bool(res.mle_retvals.get(\"converged\", True)),\n",
    "            \"noconstant\": bool(noconstant)\n",
    "        }\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# ---------- Ejecución: ajusta la ruta a tu archivo ----------\n",
    "# Ruta del .dta (cámbiala por la tuya)\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 2T\\[MT08-MT13] Microeconometría II\\Clases\\Stata\\jobtraining.dta\"\n",
    "\n",
    "df = pd.read_stata(path)\n",
    "\n",
    "# Filtros/limpieza opcional: asegurar binaria train y sin NA en variables usadas\n",
    "df = df.dropna(subset=[\"earn98\", \"train\", \"age\", \"educ\", \"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "\n",
    "res = teffects_ipw(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=[\"age\", \"educ\", \"earn96\"],\n",
    "    noconstant=True,      # <- replica \", noconstant\" de Stata\n",
    "    clip=(1e-6, 1 - 1e-6),\n",
    "    n_boot=2000,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(\"Treatment-effects estimation  (IPW ATE)\\n\")\n",
    "print(\"Estimator      : inverse-probability weights\")\n",
    "print(\"Outcome model  : weighted mean\")\n",
    "print(\"Treatment model: logit\")\n",
    "print(\"-\" * 78)\n",
    "print(f\"{'earn98':>12} | {'Coefficient':>12}  {'Std. Err.':>10}  {'z':>8}  {'P>|z|':>7}     {'[95% Conf. Interval]':>23}\")\n",
    "print(\"-\" * 78)\n",
    "ate = res[\"ATE\"]\n",
    "print(f\"{'ATE':>12} | {ate['coef']:12.6f}  {ate['se']:10.6f}  {ate['z']:8.3f}  {ate['p']:7.3f}     ({ate['ci95'][0]:.6f}, {ate['ci95'][1]:.6f})\")\n",
    "mu0 = res[\"POmean_train_0\"]\n",
    "print(f\"{'POmean 0':>12} | {mu0['coef']:12.6f}  {mu0['se']:10.6f}  {mu0['z']:8.3f}  {mu0['p']:7.3f}     ({mu0['ci95'][0]:.6f}, {mu0['ci95'][1]:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a18a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation  (IPW ATE)\n",
      "\n",
      "Estimator      : inverse-probability weights\n",
      "Outcome model  : weighted mean\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "      earn98 |  Coefficient   Std. Err.         z    P>|z|           [95% Conf. Interval]\n",
      "------------------------------------------------------------------------------\n",
      "         ATE |     1.046882    0.482386     2.170    0.030     (0.101406, 1.992358)\n",
      "    POmean 0 |     9.174996    0.274338    33.444    0.000     (8.637293, 9.712700)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# ---------- IPW con pesos normalizados ----------\n",
    "def _ipw_group_means(y, d, p):\n",
    "    # Pesos no estabilizados (ATE) y normalización por grupo\n",
    "    w1 = d / p\n",
    "    w0 = (1 - d) / (1 - p)\n",
    "    w1 = w1 / w1.sum()\n",
    "    w0 = w0 / w0.sum()\n",
    "    mu1 = np.sum(w1 * y)\n",
    "    mu0 = np.sum(w0 * y)\n",
    "    return mu1, mu0, mu1 - mu0\n",
    "\n",
    "def _fit_logit(df, d, x, noconstant=True):\n",
    "    X = df[x].copy()\n",
    "    if not noconstant:\n",
    "        X = sm.add_constant(X, has_constant=\"add\")\n",
    "    res = sm.Logit(df[d].values, X.values).fit(disp=False)\n",
    "    p = res.predict(X.values)\n",
    "    return res, p\n",
    "\n",
    "def teffects_ipw_python(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=(\"age\", \"educ\", \"earn96\"),\n",
    "    noconstant=True,\n",
    "    clip=(1e-6, 1 - 1e-6),\n",
    "    var_method=\"bootstrap\",   # \"bootstrap\" o \"none\"\n",
    "    n_boot=2000,\n",
    "    random_state=123\n",
    "):\n",
    "    # Ajuste del modelo de tratamiento\n",
    "    res, p = _fit_logit(df, d, x, noconstant=noconstant)\n",
    "    if clip is not None:\n",
    "        p = np.clip(p, clip[0], clip[1])\n",
    "\n",
    "    yv = df[y].to_numpy(dtype=float)\n",
    "    dv = df[d].to_numpy(dtype=float)\n",
    "\n",
    "    mu1, mu0, ate = _ipw_group_means(yv, dv, p)\n",
    "\n",
    "    # Varianza/SE\n",
    "    if var_method == \"bootstrap\":\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        n = len(df)\n",
    "        ate_b = np.empty(n_boot)\n",
    "        mu0_b = np.empty(n_boot)\n",
    "        idx = np.arange(n)\n",
    "\n",
    "        for b in range(n_boot):\n",
    "            ii = rng.choice(idx, size=n, replace=True)\n",
    "            df_b = df.iloc[ii]\n",
    "\n",
    "            res_b, p_b = _fit_logit(df_b, d, x, noconstant=noconstant)\n",
    "            if clip is not None:\n",
    "                p_b = np.clip(p_b, clip[0], clip[1])\n",
    "\n",
    "            yb = df_b[y].to_numpy(dtype=float)\n",
    "            db = df_b[d].to_numpy(dtype=float)\n",
    "\n",
    "            mu1_b, mu0_b[b], ate_b[b] = _ipw_group_means(yb, db, p_b)\n",
    "\n",
    "        ate_se = ate_b.std(ddof=1)\n",
    "        mu0_se = mu0_b.std(ddof=1)\n",
    "    else:\n",
    "        # Sin varianza (placeholder); podés implementar aquí una sándwich IF-based si querés calc analítico.\n",
    "        ate_se = np.nan\n",
    "        mu0_se = np.nan\n",
    "\n",
    "    # Estadísticos\n",
    "    def zpa(ci_est, se):\n",
    "        if not np.isfinite(se) or se == 0:\n",
    "            return np.nan, np.nan, (np.nan, np.nan)\n",
    "        z = ci_est / se\n",
    "        pval = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        ci = (ci_est - 1.96 * se, ci_est + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    ate_z, ate_p, ate_ci = zpa(ate, ate_se)\n",
    "    mu0_z, mu0_p, mu0_ci = zpa(mu0, mu0_se)\n",
    "\n",
    "    # Salida estilo Stata\n",
    "    print(\"Treatment-effects estimation  (IPW ATE)\\n\")\n",
    "    print(\"Estimator      : inverse-probability weights\")\n",
    "    print(\"Outcome model  : weighted mean\")\n",
    "    print(\"Treatment model: logit\")\n",
    "    print(\"-\" * 78)\n",
    "    print(f\"{y:>12} |  {'Coefficient':>11}   {'Std. Err.':>9}  {'z':>8}  {'P>|z|':>7}        {'[95% Conf. Interval]':>23}\")\n",
    "    print(\"-\" * 78)\n",
    "    print(f\"{'ATE':>12} |  {ate:11.6f}   {ate_se:9.6f}  {ate_z:8.3f}  {ate_p:7.3f}     ({ate_ci[0]:.6f}, {ate_ci[1]:.6f})\")\n",
    "    print(f\"{'POmean 0':>12} |  {mu0:11.6f}   {mu0_se:9.6f}  {mu0_z:8.3f}  {mu0_p:7.3f}     ({mu0_ci[0]:.6f}, {mu0_ci[1]:.6f})\")\n",
    "\n",
    "    return {\n",
    "        \"ATE\": dict(coef=ate, se=ate_se, z=ate_z, p=ate_p, ci95=ate_ci),\n",
    "        \"POmean_train_0\": dict(coef=mu0, se=mu0_se, z=mu0_z, p=mu0_p, ci95=mu0_ci),\n",
    "        \"treatment_model\": dict(params=dict(zip(['const']*(not noconstant)+list(x), res.params)),\n",
    "                                converged=bool(res.mle_retvals.get(\"converged\", True)),\n",
    "                                noconstant=bool(noconstant))\n",
    "    }\n",
    "\n",
    "# --------- Ejemplo de uso ----------\n",
    "\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "_ = teffects_ipw_python(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=[\"age\", \"educ\", \"earn96\"],   # <--- lista, no tupla\n",
    "    noconstant=True,\n",
    "    var_method=\"bootstrap\",\n",
    "    n_boot=5000,\n",
    "    random_state=2025\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5915f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation  (IPW ATE)\n",
      "\n",
      "Estimator      : inverse-probability weights\n",
      "Outcome model  : weighted mean\n",
      "Treatment model: logit\n",
      "----------------------------------------------------------------------------------\n",
      "      earn98 |  Coefficient   Std. Err.         z    P>|z|              [95% Conf. Interval]\n",
      "----------------------------------------------------------------------------------\n",
      "         ATE |     1.046882    0.267204     3.918    0.000     (0.523163, 1.570602)\n",
      "    POmean 0 |     9.174996    0.130275    70.428    0.000     (8.919657, 9.430336)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "def _logit_fit_pscore(df, d, x, noconstant=True):\n",
    "    X = df[list(x)].to_numpy(dtype=float)\n",
    "    if not noconstant:\n",
    "        X = sm.add_constant(X, has_constant=\"add\")\n",
    "    y = df[d].to_numpy(dtype=float)\n",
    "    mod = sm.Logit(y, X)\n",
    "    res = mod.fit(disp=False)\n",
    "    p = res.predict(X)\n",
    "    return res, X, y, p\n",
    "\n",
    "def _ipw_normalized_means(y, d, p, clip=None):\n",
    "    if clip is not None:\n",
    "        p = np.clip(p, clip[0], clip[1])\n",
    "\n",
    "    a = d / p\n",
    "    b = (1 - d) / (1 - p)\n",
    "    S1 = a.sum()\n",
    "    S0 = b.sum()\n",
    "    w1 = a / S1\n",
    "    w0 = b / S0\n",
    "\n",
    "    mu1 = np.sum(w1 * y)\n",
    "    mu0 = np.sum(w0 * y)\n",
    "    ate = mu1 - mu0\n",
    "    return mu1, mu0, ate, (w1, w0, S1, S0)\n",
    "\n",
    "def _if_beta_per_obs(X, d, p):\n",
    "    \"\"\"\n",
    "    Influence function de beta (logit MLE):\n",
    "      IF_i(beta) = J^{-1} s_i,  con s_i = x_i (d_i - p_i),\n",
    "      J = (1/n) X' W X, W = diag(p_i (1-p_i))\n",
    "    Devuelve matriz n x k con cada fila IF_i(beta).\n",
    "    \"\"\"\n",
    "    n, k = X.shape\n",
    "    w = p * (1 - p)\n",
    "    WX = X * w[:, None]\n",
    "    J = (X.T @ WX) / n\n",
    "    J_inv = np.linalg.inv(J)\n",
    "    scores = X * (d - p)[:, None]  # n x k\n",
    "    IF_beta = scores @ J_inv.T      # n x k\n",
    "    return IF_beta  # n x k\n",
    "\n",
    "def _grad_mu_normalized_beta(X, y, d, p, mu, group=\"treat1\"):\n",
    "    \"\"\"\n",
    "    Gradiente d mu_g / d beta para IPW normalizado.\n",
    "      Para g=1: a_i = d_i/p_i,  ∂a_i/∂β = - d_i * (1-p_i)/p_i * x_i\n",
    "      Para g=0: b_i = (1-d_i)/(1-p_i), ∂b_i/∂β = (1-d_i) * p_i/(1-p_i) * x_i\n",
    "      d mu_g / dβ = (1/Sg) sum_i ( ∂w_i/∂β * y_i ), con w_i = a_i/S1 o b_i/S0\n",
    "                   = (1/Sg) sum_i [ ∂a_i/∂β (y_i - mu_g) ]  (o análogo para b_i)\n",
    "    Retorna vector k.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    d = np.asarray(d)\n",
    "    p = np.asarray(p)\n",
    "    n, k = X.shape\n",
    "\n",
    "    if group == \"treat1\":\n",
    "        # g=1\n",
    "        # a_i = d/p\n",
    "        S = np.sum(d / p)\n",
    "        # ∂a_i/∂β = - d_i*(1-p_i)/p_i * x_i\n",
    "        coef = - d * (1 - p) / p\n",
    "        resid = (y - mu)  # n,\n",
    "        # sum_i ∂a_i/∂β * (y_i - mu) = sum_i [ coef_i * resid_i * x_i ]\n",
    "        term = (coef * resid)[:, None] * X\n",
    "        grad = term.sum(axis=0) / S\n",
    "        return grad  # k,\n",
    "    else:\n",
    "        # g=0\n",
    "        # b_i = (1-d)/(1-p)\n",
    "        S = np.sum((1 - d) / (1 - p))\n",
    "        # ∂b_i/∂β = (1-d_i) * p_i/(1-p_i) * x_i\n",
    "        coef = (1 - d) * p / (1 - p)\n",
    "        resid = (y - mu)\n",
    "        term = (coef * resid)[:, None] * X\n",
    "        grad = term.sum(axis=0) / S\n",
    "        return grad  # k,\n",
    "\n",
    "def _sandwich_se_ipw_normalized(X, y, d, p, clip=None):\n",
    "    \"\"\"\n",
    "    Calcula SE analíticos sándwich para:\n",
    "      - mu1_hat (IPW normalizado sobre tratados)\n",
    "      - mu0_hat (IPW normalizado sobre no tratados)\n",
    "      - ate_hat  = mu1_hat - mu0_hat\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    if clip is not None:\n",
    "        p = np.clip(p, clip[0], clip[1])\n",
    "\n",
    "    mu1, mu0, ate, (w1, w0, S1, S0) = _ipw_normalized_means(y, d, p, clip=None)\n",
    "\n",
    "    # IF directas (teniendo beta fija):\n",
    "    #   IF_i(mu1) = w1_i * (y_i - mu1)\n",
    "    #   IF_i(mu0) = w0_i * (y_i - mu0)\n",
    "    IF_mu1_direct = w1 * (y - mu1)\n",
    "    IF_mu0_direct = w0 * (y - mu0)\n",
    "    IF_ate_direct = IF_mu1_direct - IF_mu0_direct\n",
    "\n",
    "    # Influence de beta:\n",
    "    IF_beta = _if_beta_per_obs(X, d, p)  # n x k\n",
    "\n",
    "    # Gradientes d mu_g / d beta\n",
    "    g1 = _grad_mu_normalized_beta(X, y, d, p, mu1, group=\"treat1\")  # k,\n",
    "    g0 = _grad_mu_normalized_beta(X, y, d, p, mu0, group=\"treat0\")  # k,\n",
    "    gA = g1 - g0\n",
    "\n",
    "    # Termino indirecto via beta: (∂mu/∂β)' IF_i(β)\n",
    "    IF_mu1 = IF_mu1_direct + IF_beta @ g1\n",
    "    IF_mu0 = IF_mu0_direct + IF_beta @ g0\n",
    "    IF_ate = IF_ate_direct + IF_beta @ gA\n",
    "\n",
    "    # Varianzas asintóticas: Var(theta_hat) ≈ Var(IF)/n\n",
    "    def _se(IF):\n",
    "        IFc = IF - IF.mean()   # centrar por seguridad\n",
    "        var = (IFc @ IFc) / n  # promedio de cuadrados\n",
    "        return np.sqrt(var / n)\n",
    "\n",
    "    se_mu1 = _se(IF_mu1)\n",
    "    se_mu0 = _se(IF_mu0)\n",
    "    se_ate = _se(IF_ate)\n",
    "    return (mu1, se_mu1), (mu0, se_mu0), (ate, se_ate)\n",
    "\n",
    "def teffects_ipw_sandwich(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=(\"age\", \"educ\", \"earn96\"),\n",
    "    noconstant=True,\n",
    "    clip=(1e-6, 1 - 1e-6),\n",
    "):\n",
    "    # 1) Logit para p(X)\n",
    "    res, X, D, p = _logit_fit_pscore(df, d, x, noconstant=noconstant)\n",
    "    if clip is not None:\n",
    "        p = np.clip(p, clip[0], clip[1])\n",
    "    Y = df[y].to_numpy(dtype=float)\n",
    "\n",
    "    # 2) Puntos y SE analíticos (sándwich) para IPW normalizado\n",
    "    (mu1, se_mu1), (mu0, se_mu0), (ate, se_ate) = _sandwich_se_ipw_normalized(\n",
    "        X, Y, D, p, clip=None\n",
    "    )\n",
    "\n",
    "    # 3) Estadísticos\n",
    "    def zpa(theta, se):\n",
    "        z = theta / se\n",
    "        pval = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        ci = (theta - 1.96 * se, theta + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    z_ate, p_ate, ci_ate = zpa(ate, se_ate)\n",
    "    z_mu0, p_mu0, ci_mu0 = zpa(mu0, se_mu0)\n",
    "\n",
    "    # 4) Salida estilo Stata\n",
    "    print(\"Treatment-effects estimation  (IPW ATE)\\n\")\n",
    "    print(\"Estimator      : inverse-probability weights\")\n",
    "    print(\"Outcome model  : weighted mean\")\n",
    "    print(\"Treatment model: logit\")\n",
    "    print(\"-\" * 82)\n",
    "    header = f\"{y:>12} |  {'Coefficient':>11}   {'Std. Err.':>9}  {'z':>8}  {'P>|z|':>7}           {'[95% Conf. Interval]':>23}\"\n",
    "    print(header)\n",
    "    print(\"-\" * 82)\n",
    "    print(f\"{'ATE':>12} |  {ate:11.6f}   {se_ate:9.6f}  {z_ate:8.3f}  {p_ate:7.3f}     ({ci_ate[0]:.6f}, {ci_ate[1]:.6f})\")\n",
    "    print(f\"{'POmean 0':>12} |  {mu0:11.6f}   {se_mu0:9.6f}  {z_mu0:8.3f}  {p_mu0:7.3f}     ({ci_mu0[0]:.6f}, {ci_mu0[1]:.6f})\")\n",
    "\n",
    "    # (Opcional) podrías imprimir POmean 1 también:\n",
    "    # z_mu1, p_mu1, ci_mu1 = zpa(mu1, se_mu1)\n",
    "    # print(f\"{'POmean 1':>12} |  {mu1:11.6f}   {se_mu1:9.6f}  {z_mu1:8.3f}  {p_mu1:7.3f}     ({ci_mu1[0]:.6f}, {ci_mu1[1]:.6f})\")\n",
    "\n",
    "    return {\n",
    "        \"ATE\": dict(coef=float(ate), se=float(se_ate), z=float(z_ate), p=float(p_ate), ci95=ci_ate),\n",
    "        \"POmean_train_0\": dict(coef=float(mu0), se=float(se_mu0), z=float(z_mu0), p=float(p_mu0), ci95=ci_mu0),\n",
    "        \"POmean_train_1\": dict(coef=float(mu1), se=float(se_mu1)),\n",
    "        \"treatment_model\": dict(params=res.params.tolist(), converged=bool(res.mle_retvals.get(\"converged\", True)), noconstant=bool(noconstant))\n",
    "    }\n",
    "\n",
    "# ---------------- Ejemplo de uso ----------------\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 2T\\[MT08-MT13] Microeconometría II\\Clases\\Stata\\jobtraining.dta\"\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "_ = teffects_ipw_sandwich(df, y=\"earn98\", d=\"train\", x=(\"age\",\"educ\",\"earn96\"), noconstant=True, clip=(1e-6, 1-1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9401b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation                  Number of obs     =       1130\n",
      "Estimator      : augmented IPW\n",
      "Outcome model  : linear by ML\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "       earn98 | Coefficient   std. err.       z   P>|z|     [95% conf. interval]\n",
      "------------------------------------------------------------------------------\n",
      "          ATE |\n",
      "      train |   (1 vs 0)     2.880591    0.430435   6.69  0.000       2.036938      3.724244\n",
      "------------------------------------------------------------------------------\n",
      "       POmean |\n",
      "      train |          0     9.228853    0.263368  35.04  0.000       8.712651      9.745055\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "\n",
    "@dataclass\n",
    "class AIPWResult:\n",
    "    ate: float\n",
    "    ate_se: float\n",
    "    ate_ci: tuple\n",
    "    ate_z: float\n",
    "    ate_p: float\n",
    "    pomean0: float\n",
    "    pomean0_se: float\n",
    "    pomean0_ci: tuple\n",
    "    pomean0_z: float\n",
    "    pomean0_p: float\n",
    "\n",
    "def _add_intercept(X: np.ndarray):\n",
    "    return np.column_stack([np.ones(X.shape[0]), X])\n",
    "\n",
    "def _clip01(p, eps=1e-6):\n",
    "    return np.clip(p, eps, 1-eps)\n",
    "\n",
    "def teffects_aipw(df: pd.DataFrame,\n",
    "                  y_col: str = \"earn98\",\n",
    "                  d_col: str = \"train\",\n",
    "                  x_cols: list = (\"age\", \"educ\", \"earn96\"),\n",
    "                  treatment_noconstant: bool = True) -> AIPWResult:\n",
    "    \"\"\"\n",
    "    Replicates: teffects aipw (Y Xs) (D Xs, noconstant)\n",
    "      - treatment_noconstant=True -> logit without intercept (as in Stata command)\n",
    "      - outcome models are linear (OLS) with intercepts, fit separately by D.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract arrays\n",
    "    Y = df[y_col].astype(float).to_numpy()\n",
    "    D = df[d_col].astype(int).to_numpy()\n",
    "    X = df[list(x_cols)].astype(float).to_numpy()\n",
    "    n = len(Y)\n",
    "\n",
    "    # --- Propensity score model: logit(D ~ X) ---\n",
    "    Xt = X if treatment_noconstant else _add_intercept(X)\n",
    "    logit = sm.Logit(D, Xt).fit(disp=False)\n",
    "    p = _clip01(logit.predict(Xt))\n",
    "\n",
    "    # --- Outcome models: OLS with intercepts, fit separately in treated/controls ---\n",
    "    X1 = _add_intercept(X[D == 1])\n",
    "    X0 = _add_intercept(X[D == 0])\n",
    "    y1 = Y[D == 1]\n",
    "    y0 = Y[D == 0]\n",
    "\n",
    "    ols1 = sm.OLS(y1, X1).fit()\n",
    "    ols0 = sm.OLS(y0, X0).fit()\n",
    "\n",
    "    m1 = ols1.predict(_add_intercept(X))  # m1(X)\n",
    "    m0 = ols0.predict(_add_intercept(X))  # m0(X)\n",
    "\n",
    "    # --- AIPW estimators ---\n",
    "    # ATE EIF for each i:\n",
    "    psi_ate = (m1 - m0) + D * (Y - m1) / p - (1 - D) * (Y - m0) / (1 - p)\n",
    "    ate_hat = psi_ate.mean()\n",
    "    ate_se = psi_ate.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "    # POmean for D=0 (mu0) and its EIF:\n",
    "    # EIF(mu0) = m0(X) + (1-D)*(Y - m0(X))/(1-p) - mu0\n",
    "    phi_mu0 = m0 + (1 - D) * (Y - m0) / (1 - p)\n",
    "    mu0_hat = phi_mu0.mean()\n",
    "    mu0_se = phi_mu0.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "    # Inference\n",
    "    def infer(est, se):\n",
    "        z = est / se\n",
    "        pval = 2 * (1 - norm.cdf(abs(z)))\n",
    "        ci = (est - 1.96 * se, est + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    ate_z, ate_p, ate_ci = infer(ate_hat, ate_se)\n",
    "    mu0_z, mu0_p, mu0_ci = infer(mu0_hat, mu0_se)\n",
    "\n",
    "    return AIPWResult(\n",
    "        ate=ate_hat, ate_se=ate_se, ate_ci=ate_ci, ate_z=ate_z, ate_p=ate_p,\n",
    "        pomean0=mu0_hat, pomean0_se=mu0_se, pomean0_ci=mu0_ci, pomean0_z=mu0_z, pomean0_p=mu0_p\n",
    "    )\n",
    "\n",
    "def print_teffects_table(res: AIPWResult, n_obs: int):\n",
    "    # Format similar to Stata output (rounded sensibly)\n",
    "    def fmt(x): return f\"{x:>10.6f}\"\n",
    "    def fmti(x): return f\"{x:>10.6f}\"\n",
    "    print(\"Treatment-effects estimation\".ljust(46) + f\"Number of obs     = {n_obs:>10}\")\n",
    "    print(\"Estimator      : augmented IPW\")\n",
    "    print(\"Outcome model  : linear by ML\")\n",
    "    print(\"Treatment model: logit\")\n",
    "    print(\"-\" * 78)\n",
    "    print(f\"{'':13}|{'':15}Robust\")\n",
    "    print(f\"{'earn98':>13} | {'Coefficient':>11}  {'std. err.':>10}  {'z':>6}  {'P>|z|':>6}  {'[95% conf. interval]':>23}\")\n",
    "    print(\"-\" * 78)\n",
    "    # ATE row (train: 1 vs 0)\n",
    "    print(f\"{'ATE':>13} |\")\n",
    "    row = [\n",
    "        \"   (1 vs 0) \",\n",
    "        fmt(res.ate), fmt(res.ate_se),\n",
    "        f\"{res.ate_z:6.2f}\", f\"{res.ate_p:6.3f}\",\n",
    "        f\"{fmti(res.ate_ci[0])}    {fmti(res.ate_ci[1])}\"\n",
    "    ]\n",
    "    print(f\"{'train':>11} |{row[0]:>11}{row[1]:>12}{row[2]:>12}{row[3]:>7}{row[4]:>7}     {row[5]}\")\n",
    "    print(\"-\" * 78)\n",
    "    # POmean 0 row\n",
    "    print(f\"{'POmean':>13} |\")\n",
    "    row0 = [\n",
    "        \"          0 \",\n",
    "        fmt(res.pomean0), fmt(res.pomean0_se),\n",
    "        f\"{res.pomean0_z:6.2f}\", f\"{res.pomean0_p:6.3f}\",\n",
    "        f\"{fmti(res.pomean0_ci[0])}    {fmti(res.pomean0_ci[1])}\"\n",
    "    ]\n",
    "    print(f\"{'train':>11} |{row0[0]:>11}{row0[1]:>12}{row0[2]:>12}{row0[3]:>7}{row0[4]:>7}     {row0[5]}\")\n",
    "    print(\"-\" * 78)\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage (adjust df):\n",
    "# df must contain: 'earn98' (Y), 'train' (D in {0,1}), covariates: 'age','educ','earn96'\n",
    "# ---------------------------\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "res = teffects_aipw(df, y_col=\"earn98\", d_col=\"train\",\n",
    "                     x_cols=[\"age\", \"educ\", \"earn96\"],\n",
    "                     treatment_noconstant=True)\n",
    "print_teffects_table(res, n_obs=len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7ad4404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation                  Number of obs     =       1130\n",
      "Estimator      : augmented IPW\n",
      "Outcome model  : linear by ML\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "             |  Robust (bootstrap B=1000)\n",
      "       earn98 | Coefficient   std. err.       z   P>|z|     [95% conf. interval]\n",
      "------------------------------------------------------------------------------\n",
      "          ATE |\n",
      "      train |   (1 vs 0)     2.880591    0.617592   4.66  0.000       1.670112      4.091071\n",
      "------------------------------------------------------------------------------\n",
      "       POmean |\n",
      "      train |          0     9.228853    0.271437  34.00  0.000       8.696836      9.760870\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "\n",
    "# =========================\n",
    "# Núcleo AIPW (plug-in)\n",
    "# =========================\n",
    "@dataclass\n",
    "class AIPWResult:\n",
    "    ate: float\n",
    "    ate_se: float\n",
    "    ate_ci: tuple\n",
    "    ate_z: float\n",
    "    ate_p: float\n",
    "    pomean0: float\n",
    "    pomean0_se: float\n",
    "    pomean0_ci: tuple\n",
    "    pomean0_z: float\n",
    "    pomean0_p: float\n",
    "    B: int = 0\n",
    "    se_source: str = \"influence\"  # \"bootstrap\" cuando usemos Opción 1\n",
    "\n",
    "def _add_intercept(X: np.ndarray):\n",
    "    return np.column_stack([np.ones(X.shape[0]), X])\n",
    "\n",
    "def _clip01(p, eps=1e-6):\n",
    "    return np.clip(p, eps, 1-eps)\n",
    "\n",
    "def teffects_aipw(df: pd.DataFrame,\n",
    "                  y_col: str = \"earn98\",\n",
    "                  d_col: str = \"train\",\n",
    "                  x_cols: list = (\"age\", \"educ\", \"earn96\"),\n",
    "                  treatment_noconstant: bool = True) -> AIPWResult:\n",
    "    \"\"\"\n",
    "    AIPW para: teffects aipw (Y Xs) (D Xs, noconstant)\n",
    "    - logit(D ~ X) sin constante si treatment_noconstant=True\n",
    "    - OLS por separado con intercepto para Y|D=1 y Y|D=0\n",
    "    - Devuelve ATE y POmean (train=0) con SE plug-in (influence simple)\n",
    "    \"\"\"\n",
    "    Y = df[y_col].astype(float).to_numpy()\n",
    "    D = df[d_col].astype(int).to_numpy()\n",
    "    X = df[list(x_cols)].astype(float).to_numpy()\n",
    "    n = len(Y)\n",
    "\n",
    "    # Propensity: logit(D ~ X)\n",
    "    Xt = X if treatment_noconstant else _add_intercept(X)\n",
    "    logit = sm.Logit(D, Xt).fit(disp=False)\n",
    "    p = _clip01(logit.predict(Xt))\n",
    "\n",
    "    # Outcome models con intercepto\n",
    "    X1 = _add_intercept(X[D == 1])\n",
    "    X0 = _add_intercept(X[D == 0])\n",
    "    y1 = Y[D == 1]\n",
    "    y0 = Y[D == 0]\n",
    "\n",
    "    ols1 = sm.OLS(y1, X1).fit()\n",
    "    ols0 = sm.OLS(y0, X0).fit()\n",
    "\n",
    "    m1 = ols1.predict(_add_intercept(X))\n",
    "    m0 = ols0.predict(_add_intercept(X))\n",
    "\n",
    "    # EIFs y estimaciones\n",
    "    psi_ate = (m1 - m0) + D * (Y - m1) / p - (1 - D) * (Y - m0) / (1 - p)\n",
    "    ate_hat = psi_ate.mean()\n",
    "    ate_se = psi_ate.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "    phi_mu0 = m0 + (1 - D) * (Y - m0) / (1 - p)\n",
    "    mu0_hat = phi_mu0.mean()\n",
    "    mu0_se = phi_mu0.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "    def infer(est, se):\n",
    "        z = est / se\n",
    "        pval = 2 * (1 - norm.cdf(abs(z)))\n",
    "        ci = (est - 1.96 * se, est + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    ate_z, ate_p, ate_ci = infer(ate_hat, ate_se)\n",
    "    mu0_z, mu0_p, mu0_ci = infer(mu0_hat, mu0_se)\n",
    "\n",
    "    return AIPWResult(\n",
    "        ate=ate_hat, ate_se=ate_se, ate_ci=ate_ci, ate_z=ate_z, ate_p=ate_p,\n",
    "        pomean0=mu0_hat, pomean0_se=mu0_se, pomean0_ci=mu0_ci, pomean0_z=mu0_z, pomean0_p=mu0_p\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Opción 1: Bootstrap SEs\n",
    "# =========================\n",
    "def _aipw_point_estimates(df, y_col, d_col, x_cols, treatment_noconstant):\n",
    "    \"\"\"Devuelve (ATE, POmean0) para una muestra dada, re-ajustando todo.\"\"\"\n",
    "    Y = df[y_col].astype(float).to_numpy()\n",
    "    D = df[d_col].astype(int).to_numpy()\n",
    "    X = df[list(x_cols)].astype(float).to_numpy()\n",
    "\n",
    "    Xt = X if treatment_noconstant else np.column_stack([np.ones(X.shape[0]), X])\n",
    "    p = _clip01(sm.Logit(D, Xt).fit(disp=False).predict(Xt))\n",
    "\n",
    "    X1 = _add_intercept(X[D == 1]); y1 = Y[D == 1]\n",
    "    X0 = _add_intercept(X[D == 0]); y0 = Y[D == 0]\n",
    "    ols1 = sm.OLS(y1, X1).fit(); ols0 = sm.OLS(y0, X0).fit()\n",
    "\n",
    "    m1 = ols1.predict(_add_intercept(X))\n",
    "    m0 = ols0.predict(_add_intercept(X))\n",
    "\n",
    "    ate = np.mean((m1 - m0) + D*(Y - m1)/p - (1 - D)*(Y - m0)/(1 - p))\n",
    "    mu0 = np.mean(m0 + (1 - D)*(Y - m0)/(1 - p))\n",
    "    return ate, mu0\n",
    "\n",
    "def teffects_aipw_bootstrap(df: pd.DataFrame,\n",
    "                            y_col: str = \"earn98\",\n",
    "                            d_col: str = \"train\",\n",
    "                            x_cols: list = (\"age\", \"educ\", \"earn96\"),\n",
    "                            treatment_noconstant: bool = True,\n",
    "                            B: int = 500,\n",
    "                            seed: int = 123) -> AIPWResult:\n",
    "    \"\"\"\n",
    "    Calcula SEs por bootstrap para ATE y POmean0.\n",
    "    - Re-muestrea filas con reemplazo y re-ajusta logit + OLS en cada réplica.\n",
    "    - Devuelve las mismas métricas (z, p, CI) usando SE_bootstrap (normal-approx).\n",
    "    \"\"\"\n",
    "    # Estimación puntual en muestra completa\n",
    "    base_res = teffects_aipw(df, y_col, d_col, x_cols, treatment_noconstant)\n",
    "    ate_hat, mu0_hat = base_res.ate, base_res.pomean0\n",
    "\n",
    "    # Bootstrap\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(df)\n",
    "    ate_b = np.empty(B); mu0_b = np.empty(B)\n",
    "\n",
    "    for b in range(B):\n",
    "        idx = rng.integers(low=0, high=n, size=n)\n",
    "        samp = df.iloc[idx].reset_index(drop=True)\n",
    "        ate_b[b], mu0_b[b] = _aipw_point_estimates(\n",
    "            samp, y_col, d_col, x_cols, treatment_noconstant\n",
    "        )\n",
    "\n",
    "    ate_se = ate_b.std(ddof=1)\n",
    "    mu0_se = mu0_b.std(ddof=1)\n",
    "\n",
    "    # Inferencia normal (como Stata reporta en teffects)\n",
    "    def infer(est, se):\n",
    "        z = est / se\n",
    "        pval = 2 * (1 - norm.cdf(abs(z)))\n",
    "        ci = (est - 1.96 * se, est + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    ate_z, ate_p, ate_ci = infer(ate_hat, ate_se)\n",
    "    mu0_z, mu0_p, mu0_ci = infer(mu0_hat, mu0_se)\n",
    "\n",
    "    return AIPWResult(\n",
    "        ate=ate_hat, ate_se=ate_se, ate_ci=ate_ci, ate_z=ate_z, ate_p=ate_p,\n",
    "        pomean0=mu0_hat, pomean0_se=mu0_se, pomean0_ci=mu0_ci, pomean0_z=mu0_z, pomean0_p=mu0_p,\n",
    "        B=B, se_source=\"bootstrap\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Impresión estilo Stata\n",
    "# =========================\n",
    "def print_teffects_table(res: AIPWResult, n_obs: int):\n",
    "    def fmt(x): return f\"{x:>10.6f}\"\n",
    "    def fmti(x): return f\"{x:>10.6f}\"\n",
    "    print(f\"Treatment-effects estimation\".ljust(46) + f\"Number of obs     = {n_obs:>10}\")\n",
    "    print(\"Estimator      : augmented IPW\")\n",
    "    print(\"Outcome model  : linear by ML\")\n",
    "    print(\"Treatment model: logit\")\n",
    "    label = \"Robust (bootstrap B={})\".format(res.B) if res.se_source == \"bootstrap\" else \"Robust\"\n",
    "    print(\"-\" * 78)\n",
    "    print(f\"{'':13}|{label:>27}\")\n",
    "    print(f\"{'earn98':>13} | {'Coefficient':>11}  {'std. err.':>10}  {'z':>6}  {'P>|z|':>6}  {'[95% conf. interval]':>23}\")\n",
    "    print(\"-\" * 78)\n",
    "    # ATE\n",
    "    print(f\"{'ATE':>13} |\")\n",
    "    row = [\n",
    "        \"   (1 vs 0) \",\n",
    "        fmt(res.ate), fmt(res.ate_se),\n",
    "        f\"{res.ate_z:6.2f}\", f\"{res.ate_p:6.3f}\",\n",
    "        f\"{fmti(res.ate_ci[0])}    {fmti(res.ate_ci[1])}\"\n",
    "    ]\n",
    "    print(f\"{'train':>11} |{row[0]:>11}{row[1]:>12}{row[2]:>12}{row[3]:>7}{row[4]:>7}     {row[5]}\")\n",
    "    print(\"-\" * 78)\n",
    "    # POmean 0\n",
    "    print(f\"{'POmean':>13} |\")\n",
    "    row0 = [\n",
    "        \"          0 \",\n",
    "        fmt(res.pomean0), fmt(res.pomean0_se),\n",
    "        f\"{res.pomean0_z:6.2f}\", f\"{res.pomean0_p:6.3f}\",\n",
    "        f\"{fmti(res.pomean0_ci[0])}    {fmti(res.pomean0_ci[1])}\"\n",
    "    ]\n",
    "    print(f\"{'train':>11} |{row0[0]:>11}{row0[1]:>12}{row0[2]:>12}{row0[3]:>7}{row0[4]:>7}     {row0[5]}\")\n",
    "    print(\"-\" * 78)\n",
    "\n",
    "# =========================\n",
    "# Ejemplo de uso\n",
    "# =========================\n",
    "# df: DataFrame con columnas 'earn98' (Y), 'train' (D en {0,1}), 'age','educ','earn96'.\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "res = teffects_aipw_bootstrap(\n",
    "    df,\n",
    "    y_col=\"earn98\",\n",
    "    d_col=\"train\",\n",
    "    x_cols=[\"age\", \"educ\", \"earn96\"],\n",
    "    treatment_noconstant=True,\n",
    "    B=1000,   # aumentar para mayor precisión\n",
    "    seed=123\n",
    ")\n",
    "print_teffects_table(res, n_obs=len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab84a596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation (IPWRA ATE)\n",
      "Estimator      : IPW regression adjustment\n",
      "Outcome model  : linear\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "ATE        |   2.880601     0.430412     6.69    0.000\n",
      "POmean 0   |   9.228870\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from scipy.stats import norm  # ✅ import correcto para cdf\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Datos\n",
    "# -------------------------------------------------------------\n",
    "# Ejemplo: df = pd.read_stata('lalonde.dta')\n",
    "# Variables: earn98 (Y), train (D), age educ earn96 (X)\n",
    "\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "\n",
    "y = df['earn98'].to_numpy()\n",
    "t = df['train'].to_numpy()\n",
    "X = df[['age', 'educ', 'earn96']].to_numpy()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Modelo de tratamiento (propensity score)\n",
    "# -------------------------------------------------------------\n",
    "logit = LogisticRegression(fit_intercept=False, solver='lbfgs')\n",
    "ps = logit.fit(X, t).predict_proba(X)[:, 1]\n",
    "ps = np.clip(ps, 1e-6, 1 - 1e-6)  # evitar extremos\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Modelo de outcome por grupo\n",
    "# -------------------------------------------------------------\n",
    "reg_treat = LinearRegression(fit_intercept=True).fit(X[t == 1], y[t == 1])\n",
    "reg_ctrl  = LinearRegression(fit_intercept=True).fit(X[t == 0], y[t == 0])\n",
    "\n",
    "mu1 = reg_treat.predict(X)\n",
    "mu0 = reg_ctrl.predict(X)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. IPWRA (Augmented IPW)\n",
    "# -------------------------------------------------------------\n",
    "ate_i = (t * (y - mu1) / ps) - ((1 - t) * (y - mu0) / (1 - ps)) + (mu1 - mu0)\n",
    "ate = np.mean(ate_i)\n",
    "\n",
    "pomean0_i = (1 - t) * (y - mu0) / (1 - ps) + mu0\n",
    "pomean0 = np.mean(pomean0_i)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Varianza robusta tipo sándwich\n",
    "# -------------------------------------------------------------\n",
    "v_ate = np.var(ate_i, ddof=1) / len(ate_i)\n",
    "se_ate = np.sqrt(v_ate)\n",
    "\n",
    "z_ate = ate / se_ate\n",
    "p_ate = 2 * (1 - norm.cdf(abs(z_ate)))  # ✅ ahora sí\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Mostrar resultados\n",
    "# -------------------------------------------------------------\n",
    "print(\"Treatment-effects estimation (IPWRA ATE)\")\n",
    "print(\"Estimator      : IPW regression adjustment\")\n",
    "print(\"Outcome model  : linear\")\n",
    "print(\"Treatment model: logit\")\n",
    "print(\"-\" * 78)\n",
    "print(f\"{'ATE':<10} | {ate:10.6f}   {se_ate:10.6f}   {z_ate:6.2f}   {p_ate:6.3f}\")\n",
    "print(f\"{'POmean 0':<10} | {pomean0:10.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5382414d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation (IPWRA ATE — stacked M-estimator)\n",
      "Estimator      : IPW regression adjustment (joint EE)\n",
      "Outcome model  : linear (OLS with intercept)\n",
      "Treatment model: logit (no constant)\n",
      "Number of obs  : 1130\n",
      "------------------------------------------------------------------------------\n",
      "ATE        |    2.880591     0.594358     4.85    0.000\n",
      "POmean 0   |    9.228853     0.268473    34.38    0.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import root\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Utilidades\n",
    "# ------------------------------------------------------------\n",
    "def sigmoid(u):\n",
    "    # estabilidad numérica\n",
    "    out = np.empty_like(u)\n",
    "    pos = u >= 0\n",
    "    neg = ~pos\n",
    "    out[pos] = 1.0 / (1.0 + np.exp(-u[pos]))\n",
    "    e = np.exp(u[neg])\n",
    "    out[neg] = e / (1.0 + e)\n",
    "    return out\n",
    "\n",
    "def clip01(p, eps=1e-8):\n",
    "    return np.minimum(1 - eps, np.maximum(eps, p))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Momentos apilados (EE) tipo GMM/M-estimator\n",
    "# θ = [α (k), γ1 (k+1), γ0 (k+1), δ (ATE), m0 (POmean0)]\n",
    "#   α:     coef. logit (sin intercepto)    dimensión k\n",
    "#   γ1:    OLS tratados (con intercepto)   dimensión k+1\n",
    "#   γ0:    OLS controles (con intercepto)  dimensión k+1\n",
    "#   δ:     ATE\n",
    "#   m0:    POmean(0)\n",
    "# ------------------------------------------------------------\n",
    "class IPWRA_MEstimator:\n",
    "    def __init__(self, df, y_col=\"earn98\", d_col=\"train\", x_cols=(\"age\",\"educ\",\"earn96\"),\n",
    "                 eps_ps=1e-8):\n",
    "        self.df = df.dropna(subset=[y_col, d_col] + list(x_cols)).copy()\n",
    "        self.y = self.df[y_col].to_numpy(float)\n",
    "        self.d = (self.df[d_col].astype(int) > 0).astype(int).to_numpy()\n",
    "        self.X = self.df[list(x_cols)].to_numpy(float)             # (n,k)\n",
    "        self.n, self.k = self.X.shape\n",
    "        self.Z = np.column_stack([np.ones(self.n), self.X])       # (n,k+1) para OLS con intercepto\n",
    "        self.eps = eps_ps\n",
    "\n",
    "    def unpack_theta(self, theta):\n",
    "        k = self.k\n",
    "        a  = theta[0:k]                       # α\n",
    "        g1 = theta[k: k + (k+1)]              # γ1\n",
    "        g0 = theta[k + (k+1): k + 2*(k+1)]    # γ0\n",
    "        delta = theta[k + 2*(k+1)]            # δ\n",
    "        m0    = theta[k + 2*(k+1) + 1]        # m0\n",
    "        return a, g1, g0, delta, m0\n",
    "\n",
    "    def moments_i(self, theta):\n",
    "        \"\"\"\n",
    "        Devuelve g_i(θ) de dimensión:\n",
    "           k                        (logit, sin intercepto)\n",
    "         + (k+1)                    (OLS tratados)\n",
    "         + (k+1)                    (OLS controles)\n",
    "         + 1                        (ATE EIF - δ)\n",
    "         + 1                        (POmean0 EIF - m0)\n",
    "        total: 2k + 3 + 2 = 2k + 5\n",
    "        \"\"\"\n",
    "        a, g1, g0, delta, m0 = self.unpack_theta(theta)\n",
    "\n",
    "        X, Z, y, d, eps = self.X, self.Z, self.y, self.d, self.eps\n",
    "        k = self.k\n",
    "\n",
    "        # ps(x; α)  (logit sin constante)\n",
    "        ps = clip01(sigmoid(X @ a), eps)\n",
    "\n",
    "        # μ1(x; γ1) y μ0(x; γ0)  (lineales con intercepto)\n",
    "        mu1 = Z @ g1\n",
    "        mu0 = Z @ g0\n",
    "\n",
    "        # Residuos outcome\n",
    "        e1 = y - mu1\n",
    "        e0 = y - mu0\n",
    "\n",
    "        # ----- Bloques de momentos por observación i -----\n",
    "\n",
    "        # 1) Logit: ∑ x_i (d_i - ps_i) = 0  (k)\n",
    "        g_logit = X * (d - ps)[:, None]                  # (n,k)\n",
    "\n",
    "        # 2) OLS tratados: ∑ d_i * z_i * e1_i = 0  (k+1)\n",
    "        g_ols1 = Z * (d * e1)[:, None]                   # (n,k+1)\n",
    "\n",
    "        # 3) OLS controles: ∑ (1-d_i) * z_i * e0_i = 0  (k+1)\n",
    "        g_ols0 = Z * ((1 - d) * e0)[:, None]             # (n,k+1)\n",
    "\n",
    "        # 4) ATE (EIF): ∑ [ d*(y-μ1)/ps - (1-d)*(y-μ0)/(1-ps) + (μ1-μ0) - δ ] = 0  (1)\n",
    "        g_ate = (d * (y - mu1) / ps) - ((1 - d) * (y - mu0) / (1 - ps)) + (mu1 - mu0) - delta  # (n,)\n",
    "\n",
    "        # 5) POmean(0) (EIF): ∑ [ (1-d)*(y-μ0)/(1-ps) + μ0 - m0 ] = 0  (1)\n",
    "        g_p0  = ((1 - d) * (y - mu0) / (1 - ps)) + mu0 - m0                                   # (n,)\n",
    "\n",
    "        # Apilar por fila (i) → vector g_i(θ)\n",
    "        # Orden: [logit(k), ols1(k+1), ols0(k+1), ate(1), p0(1)]\n",
    "        gi = np.column_stack([\n",
    "            g_logit,\n",
    "            g_ols1,\n",
    "            g_ols0,\n",
    "            g_ate.reshape(-1,1),\n",
    "            g_p0.reshape(-1,1)\n",
    "        ])  # (n, 2k+5)\n",
    "\n",
    "        return gi\n",
    "\n",
    "    def moments_mean(self, theta):\n",
    "        gi = self.moments_i(theta)\n",
    "        return gi.mean(axis=0)\n",
    "\n",
    "    # Jacobiano por diferencia finita: A = ∂ \\bar g / ∂θ\n",
    "    def jacobian(self, theta, h=1e-6):\n",
    "        g0 = self.moments_mean(theta)\n",
    "        p = theta.size\n",
    "        A = np.zeros((g0.size, p))\n",
    "        for j in range(p):\n",
    "            th = theta.copy()\n",
    "            step = h * (1.0 + abs(theta[j]))\n",
    "            th[j] += step\n",
    "            gj = self.moments_mean(th)\n",
    "            A[:, j] = (gj - g0) / step\n",
    "        return A\n",
    "\n",
    "    def fit(self, init=None, tol=1e-10, verbose=False):\n",
    "        n, k = self.n, self.k\n",
    "\n",
    "        # ----- Inicialización razonable -----\n",
    "        if init is None:\n",
    "            # Logit (separado) para α (sin intercepto)\n",
    "            # Usamos mínimos cuadrados para iniciar α (logit con link aproximado)\n",
    "            # y luego una actualización de Newton simple.\n",
    "            # Mejor: pseudo-sols con una pasada de IRLS.\n",
    "            a0 = np.zeros(k)\n",
    "            # OLS por grupo para γ1 y γ0\n",
    "            Z = self.Z\n",
    "            y = self.y\n",
    "            d = self.d\n",
    "\n",
    "            # Tratados\n",
    "            if d.sum() == 0 or d.sum() == n:\n",
    "                raise ValueError(\"Tratamiento es degenerado (todo 0 o todo 1).\")\n",
    "            g1_0 = np.linalg.lstsq(Z[d==1], y[d==1], rcond=None)[0]\n",
    "            g0_0 = np.linalg.lstsq(Z[d==0], y[d==0], rcond=None)[0]\n",
    "\n",
    "            # Plug-in para δ y m0\n",
    "            ps0 = clip01(sigmoid(self.X @ a0), self.eps)\n",
    "            mu1_0 = Z @ g1_0\n",
    "            mu0_0 = Z @ g0_0\n",
    "\n",
    "            ate_i0 = d*(y-mu1_0)/ps0 - (1-d)*(y-mu0_0)/(1-ps0) + (mu1_0 - mu0_0)\n",
    "            delta0 = ate_i0.mean()\n",
    "\n",
    "            p0_i0 = (1-d)*(y-mu0_0)/(1-ps0) + mu0_0\n",
    "            m0_0  = p0_i0.mean()\n",
    "\n",
    "            init = np.concatenate([a0, g1_0, g0_0, [delta0, m0_0]])\n",
    "\n",
    "        # ----- Resolver EE: mean(g_i(θ)) = 0 -----\n",
    "        sol = root(lambda th: self.moments_mean(th), init, tol=tol, method='hybr')\n",
    "        if not sol.success and verbose:\n",
    "            print(\"root() no convergió:\", sol.message)\n",
    "\n",
    "        theta_hat = sol.x\n",
    "\n",
    "        # ----- Varianza sándwich -----\n",
    "        gi = self.moments_i(theta_hat)                   # (n, q)\n",
    "        gbar = gi.mean(axis=0)                           # ≈ 0\n",
    "        B = (gi - gbar).T @ (gi - gbar) / n              # “meat” (q x q)\n",
    "        A = self.jacobian(theta_hat)                     # (q x p); aquí q==p == 2k+5\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        V = (A_inv @ B @ A_inv.T) / n                    # Var(θ_hat)\n",
    "        se = np.sqrt(np.diag(V))\n",
    "\n",
    "        # indices de δ y m0\n",
    "        idx_delta = k + 2*(k+1)\n",
    "        idx_m0    = idx_delta + 1\n",
    "\n",
    "        res = {\n",
    "            \"theta\": theta_hat,\n",
    "            \"V\": V,\n",
    "            \"se\": se,\n",
    "            \"A\": A,\n",
    "            \"B\": B,\n",
    "            \"n\": n,\n",
    "            \"k\": k,\n",
    "            \"idx\": {\"alpha\": (0, k),\n",
    "                    \"gamma1\": (k, k+(k+1)),\n",
    "                    \"gamma0\": (k+(k+1), k+2*(k+1)),\n",
    "                    \"delta\": idx_delta,\n",
    "                    \"m0\": idx_m0}\n",
    "        }\n",
    "        return res\n",
    "\n",
    "def summarize_ipwra_mest(res, est):\n",
    "    n, k = res[\"n\"], res[\"k\"]\n",
    "    idx = res[\"idx\"]\n",
    "    th, se = res[\"theta\"], res[\"se\"]\n",
    "\n",
    "    delta, se_delta = th[idx[\"delta\"]], se[idx[\"delta\"]]\n",
    "    z_delta = delta / se_delta\n",
    "    p_delta = 2*(1 - norm.cdf(abs(z_delta)))\n",
    "\n",
    "    m0, se_m0 = th[idx[\"m0\"]], se[idx[\"m0\"]]\n",
    "    z_m0 = m0 / se_m0\n",
    "    p_m0 = 2*(1 - norm.cdf(abs(z_m0)))\n",
    "\n",
    "    print(\"Treatment-effects estimation (IPWRA ATE — stacked M-estimator)\")\n",
    "    print(\"Estimator      : IPW regression adjustment (joint EE)\")\n",
    "    print(\"Outcome model  : linear (OLS with intercept)\")\n",
    "    print(\"Treatment model: logit (no constant)\")\n",
    "    print(f\"Number of obs  : {n}\")\n",
    "    print(\"-\"*78)\n",
    "    print(f\"{'ATE':<11}| {delta:11.6f}   {se_delta:10.6f}   {z_delta:6.2f}   {p_delta:6.3f}\")\n",
    "    print(f\"{'POmean 0':<11}| {m0:11.6f}   {se_m0:10.6f}   {z_m0:6.2f}   {p_m0:6.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Uso\n",
    "# ------------------------------------------------------------\n",
    "# df = pd.read_stata(\"lalonde.dta\")  # o tu DataFrame ya preparado\n",
    "\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "\n",
    "mest = IPWRA_MEstimator(df, y_col=\"earn98\", d_col=\"train\", x_cols=(\"age\",\"educ\",\"earn96\"))\n",
    "res  = mest.fit(tol=1e-10, verbose=True)\n",
    "summarize_ipwra_mest(res, mest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cae2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Endogenous Treatment Effects (Stata: `eteffects`) via stacked GMM\n",
    "# ============================================================\n",
    "# Reproduce: eteffects (earn98 age educ earn96) (train age educ earn96)\n",
    "# Reqs: pip install numpy pandas statsmodels scipy\n",
    "# Python 3.10+ recomendado\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "from math import erf, sqrt\n",
    "\n",
    "# -------------------------\n",
    "# Utilidades\n",
    "# -------------------------\n",
    "def mills_terms(eta):\n",
    "    \"\"\"Inverse Mills for probit control function.\"\"\"\n",
    "    Phi = norm.cdf(eta)\n",
    "    phi = norm.pdf(eta)\n",
    "    eps = 1e-12\n",
    "    l1 = phi / np.clip(Phi, eps, 1 - eps)        # μ(1,Z;γ)\n",
    "    l0 = -phi / np.clip(1 - Phi, eps, 1 - eps)   # μ(0,Z;γ)\n",
    "    return l1, l0\n",
    "\n",
    "def z2p(z):\n",
    "    return 2 * (1 - 0.5 * (1 + erf(abs(z)/sqrt(2))))\n",
    "\n",
    "@dataclass\n",
    "class ETE_GMM_Results:\n",
    "    n: int\n",
    "    params: pd.Series            # [alpha, b_age, b_educ, b_earn96, theta_cf, gamma_0..k]\n",
    "    vcov_gmm: pd.DataFrame\n",
    "    ate: float\n",
    "    ate_se_boot: float\n",
    "    ate_ci: tuple\n",
    "    pomean0: float\n",
    "    pomean0_se_boot: float\n",
    "    pomean0_ci: tuple\n",
    "    conv: dict\n",
    "\n",
    "# -------------------------\n",
    "# Clase GMM con momentos apilados\n",
    "# -------------------------\n",
    "class ETE_GMM(GMM):\n",
    "    \"\"\"\n",
    "    Parámetros θ = [α, β (p), θ_cf, γ (k)]\n",
    "    Momentos:\n",
    "      m_probit: Z * (D - Φ(Zγ))                 -> k momentos\n",
    "      m_out   : W * (Y - αD - Xβ - θ_cf μ)      -> (p+2) momentos, W=[1,D,X]\n",
    "    \"\"\"\n",
    "    def __init__(self, endog, exog_out, treat, exog_treat, **kw):\n",
    "        # Datos\n",
    "        self.Y = np.asarray(endog).reshape(-1, 1)\n",
    "        self.D = np.asarray(treat).reshape(-1, 1)\n",
    "        self.X = np.asarray(exog_out)           # p cols (SIN constante)\n",
    "        self.Z = np.asarray(exog_treat)         # k cols (CON constante)\n",
    "        self.W = np.column_stack([np.ones((self.Y.shape[0], 1)), self.D, self.X])\n",
    "        self.p = self.X.shape[1]\n",
    "        self.k = self.Z.shape[1]\n",
    "\n",
    "        # FIX: placeholders para que GMM tenga xnames y no falle\n",
    "        n = self.Y.shape[0]\n",
    "        exog_placeholder = np.ones((n, 1))\n",
    "        instrument_placeholder = np.ones((n, 1))\n",
    "\n",
    "        start = np.zeros(1 + self.p + 1 + self.k)\n",
    "        super().__init__(\n",
    "            endog=np.zeros((n, 1)),\n",
    "            exog=exog_placeholder,\n",
    "            instrument=instrument_placeholder,\n",
    "            k_moms=self.k + (self.p + 2),\n",
    "            k_params=start.size,\n",
    "            **kw\n",
    "        )\n",
    "\n",
    "    def momcond(self, params):\n",
    "        alpha = params[0]\n",
    "        beta  = params[1:1 + self.p]\n",
    "        theta = params[1 + self.p]\n",
    "        gamma = params[1 + self.p + 1:]\n",
    "\n",
    "        eta = self.Z @ gamma\n",
    "        l1, l0 = mills_terms(eta)\n",
    "        mu = np.where(self.D.ravel() == 1, l1, l0).reshape(-1, 1)\n",
    "\n",
    "        # Probit moments\n",
    "        Phi = norm.cdf(eta).reshape(-1, 1)\n",
    "        m1 = (self.Z * (self.D - Phi))          # n x k\n",
    "\n",
    "        # Outcome moments\n",
    "        yhat = alpha * self.D + self.X @ beta.reshape(-1, 1) + theta * mu\n",
    "        e = self.Y - yhat                        # n x 1\n",
    "        m2 = self.W * e                          # n x (p+2)\n",
    "\n",
    "        return np.column_stack([m1, m2])\n",
    "\n",
    "# -------------------------\n",
    "# Estimación principal\n",
    "# -------------------------\n",
    "def eteffects_gmm(df, y='earn98', d='train',\n",
    "                  x_vars=['age','educ','earn96'],\n",
    "                  z_vars=['age','educ','earn96'],\n",
    "                  n_boot=1000, random_state=123, maxiter=2, wargs=None):\n",
    "    # Matrices: X sin constante; Z CON constante (probit)\n",
    "    Y = df[y].to_numpy()\n",
    "    D = df[d].astype(int).to_numpy()\n",
    "    X = df[x_vars].to_numpy()\n",
    "    Z = sm.add_constant(df[z_vars], has_constant='add').to_numpy()\n",
    "\n",
    "    # Modelo GMM\n",
    "    model = ETE_GMM(endog=Y, exog_out=X, treat=D, exog_treat=Z)\n",
    "\n",
    "    # Inicialización: probit + OLS con CF\n",
    "    probit_start = sm.Probit(D, Z).fit(disp=False)\n",
    "    gamma0 = probit_start.params\n",
    "    eta0 = Z @ gamma0\n",
    "    l1, l0 = mills_terms(eta0)\n",
    "    mu0 = np.where(D == 1, l1, l0)\n",
    "\n",
    "    W_cf = np.column_stack([np.ones_like(D), D, X, mu0])\n",
    "    ols0 = sm.OLS(Y, W_cf).fit()\n",
    "    alpha0 = ols0.params[1]\n",
    "    beta0  = ols0.params[2:2 + X.shape[1]]\n",
    "    theta0 = ols0.params[-1]\n",
    "    start = np.r_[alpha0, beta0, theta0, gamma0]\n",
    "\n",
    "    # Two-step efficient GMM\n",
    "    res = model.fit(\n",
    "        start,\n",
    "        maxiter=maxiter,\n",
    "        inv_weights=None,\n",
    "        weights_method='cov',\n",
    "        optim_method='bfgs',\n",
    "        optim_args={'disp': False}\n",
    "    )\n",
    "\n",
    "    params = res.params\n",
    "    vcov = res.cov_params()\n",
    "\n",
    "    # Funcionales (evaluados en θ_hat)\n",
    "    alpha = params[0]\n",
    "    beta  = params[1:1 + X.shape[1]]\n",
    "    theta = params[1 + X.shape[1]]\n",
    "    gamma = params[1 + X.shape[1] + 1:]\n",
    "\n",
    "    eta = Z @ gamma\n",
    "    l1, l0 = mills_terms(eta)\n",
    "    delta_mu = l1 - l0\n",
    "\n",
    "    y0_i = (X @ beta) + theta * l0\n",
    "    ATE = float(alpha + theta * np.mean(delta_mu))\n",
    "    P0  = float(np.mean(y0_i))\n",
    "\n",
    "    # Bootstrap para SE de ATE y POmean(0)\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    n = len(df)\n",
    "    ate_bs = np.empty(n_boot)\n",
    "    p0_bs  = np.empty(n_boot)\n",
    "\n",
    "    for b in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        dfr = df.iloc[idx].reset_index(drop=True)\n",
    "\n",
    "        Yb = dfr[y].to_numpy()\n",
    "        Db = dfr[d].astype(int).to_numpy()\n",
    "        Xb = dfr[x_vars].to_numpy()\n",
    "        Zb = sm.add_constant(dfr[z_vars], has_constant='add').to_numpy()\n",
    "\n",
    "        model_b = ETE_GMM(Yb, Xb, Db, Zb)\n",
    "\n",
    "        # inicios bootstrap\n",
    "        probit_b = sm.Probit(Db, Zb).fit(disp=False)\n",
    "        g0 = probit_b.params\n",
    "        et0 = Zb @ g0\n",
    "        l1b, l0b = mills_terms(et0)\n",
    "        mu0b = np.where(Db == 1, l1b, l0b)\n",
    "        Wcfb = np.column_stack([np.ones_like(Db), Db, Xb, mu0b])\n",
    "        ols_b = sm.OLS(Yb, Wcfb).fit()\n",
    "        s_b = np.r_[ols_b.params[1], ols_b.params[2:2 + Xb.shape[1]], ols_b.params[-1], g0]\n",
    "\n",
    "        try:\n",
    "            rb = model_b.fit(\n",
    "                s_b,\n",
    "                maxiter=maxiter,\n",
    "                inv_weights=None,\n",
    "                weights_method='cov',\n",
    "                optim_method='bfgs',\n",
    "                optim_args={'disp': False}\n",
    "            )\n",
    "            parb = rb.params\n",
    "        except Exception:\n",
    "            parb = s_b  # fallback si no converge\n",
    "\n",
    "        ab = parb[0]\n",
    "        bb = parb[1:1 + Xb.shape[1]]\n",
    "        tb = parb[1 + Xb.shape[1]]\n",
    "        gb = parb[1 + Xb.shape[1] + 1:]\n",
    "\n",
    "        etb = Zb @ gb\n",
    "        l1b, l0b = mills_terms(etb)\n",
    "        ate_bs[b] = float(ab + tb * np.mean(l1b - l0b))\n",
    "        p0_bs[b]  = float(np.mean(Xb @ bb + tb * l0b))\n",
    "\n",
    "    ate_se = float(np.std(ate_bs, ddof=1))\n",
    "    p0_se  = float(np.std(p0_bs, ddof=1))\n",
    "    z_95 = 1.959963984540054\n",
    "    ate_ci = (ATE - z_95*ate_se, ATE + z_95*ate_se)\n",
    "    p0_ci  = (P0  - z_95*p0_se , P0  + z_95*p0_se )\n",
    "\n",
    "    return ETE_GMM_Results(\n",
    "        n=n,\n",
    "        params=pd.Series(\n",
    "            params,\n",
    "            index=(['alpha'] + [f'b_{v}' for v in x_vars] + ['theta_cf'] + [f'gamma_{i}' for i in range(Z.shape[1])])\n",
    "        ),\n",
    "        vcov_gmm=pd.DataFrame(vcov),\n",
    "        ate=ATE, ate_se_boot=ate_se, ate_ci=ate_ci,\n",
    "        pomean0=P0, pomean0_se_boot=p0_se, pomean0_ci=p0_ci,\n",
    "        conv={'success': res.converged, 'message': str(res.message)}\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# Pretty print (opcional)\n",
    "# -------------------------\n",
    "def print_eteffects(res: ETE_GMM_Results):\n",
    "    print(f\"Endogenous treatment-effects estimation    Number of obs = {res.n}\\n\")\n",
    "    print(\"Outcome model: linear\")\n",
    "    print(\"Treatment model: probit\\n\")\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"             |               Robust (bootstrap for functionals)\")\n",
    "    print(\"   earn98    |  Coefficient   Std. Err.       z     P>|z|           [95% Conf. Interval]\")\n",
    "    print(\"-------------+------------------------------------------------\")\n",
    "    z = res.ate / res.ate_se_boot\n",
    "    p = z2p(z)\n",
    "    print(f\"ATE (1 vs 0) | {res.ate:10.5f}   {res.ate_se_boot:9.5f}   {z:7.2f}   {p:0.3f}    ({res.ate_ci[0]:.5f}, {res.ate_ci[1]:.5f})\")\n",
    "    print(\"-------------+------------------------------------------------\")\n",
    "    z0 = res.pomean0 / res.pomean0_se_boot\n",
    "    p0 = z2p(z0)\n",
    "    print(f\"POmean 0     | {res.pomean0:10.5f}   {res.pomean0_se_boot:9.5f}   {z0:7.2f}   {p0:0.3f}    ({res.pomean0_ci[0]:.5f}, {res.pomean0_ci[1]:.5f})\")\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "    print(\"Convergence:\", res.conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "affe587f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata(path)\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearn98\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meduc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearn96\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43meteffects_gmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndogenous treatment-effects estimation    Number of obs = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutcome model: linear\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTreatment model: probit\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 131\u001b[0m, in \u001b[0;36meteffects_gmm\u001b[1;34m(df, y, d, x_vars, z_vars, n_boot, random_state, maxiter, wargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m start \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mr_[alpha0, beta0, theta0, gamma0]\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# Two-step efficient GMM\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43minv_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcov\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbfgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m params \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m    141\u001b[0m vcov \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mcov_params()\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py:697\u001b[0m, in \u001b[0;36mGMM.fit\u001b[1;34m(self, start_params, maxiter, inv_weights, weights_method, wargs, has_optimal_weights, optim_method, optim_args)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# check that we have the right number of xnames\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fix_param_names(params, param_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 697\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mresults_class_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moptions_other\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptions_other\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m                                \u001b[49m\u001b[43moptim_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptim_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m results \u001b[38;5;66;03m# FIXME: remove, still keeping it temporarily\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py:1132\u001b[0m, in \u001b[0;36mGMMResults.__init__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnobs\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_resid \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m-> 1132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_params_default \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cov_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py:1165\u001b[0m, in \u001b[0;36mGMMResults._cov_params\u001b[1;34m(self, **kwds)\u001b[0m\n\u001b[0;32m   1163\u001b[0m gradmoms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgradient_momcond(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m   1164\u001b[0m moms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmomcond(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m-> 1165\u001b[0m covparams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_cov_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradmoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m covparams\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\sandbox\\regression\\gmm.py:1212\u001b[0m, in \u001b[0;36mGMMResults.calc_cov_params\u001b[1;34m(self, moms, gradmoms, weights, use_weights, has_optimal_weights, weights_method, wargs)\u001b[0m\n\u001b[0;32m   1203\u001b[0m     omegahat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcalc_weightmatrix(\n\u001b[0;32m   1204\u001b[0m                                         moms,\n\u001b[0;32m   1205\u001b[0m                                         weights_method\u001b[38;5;241m=\u001b[39mweights_method,\n\u001b[0;32m   1206\u001b[0m                                         wargs\u001b[38;5;241m=\u001b[39mwargs,\n\u001b[0;32m   1207\u001b[0m                                         params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_optimal_weights: \u001b[38;5;66;03m#has_optimal_weights:\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# TOD0 make has_optimal_weights depend on convergence or iter >2\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     cov \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradmoms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43momegahat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradmoms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1215\u001b[0m     gw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(gradmoms\u001b[38;5;241m.\u001b[39mT, weights)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:608\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    605\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m errstate(call\u001b[38;5;241m=\u001b[39m_raise_linalgerror_singular, invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    607\u001b[0m               over\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, divide\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, under\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 608\u001b[0m     ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:104\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# Cargar datos y limpiar como hiciste\n",
    "\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "\n",
    "res = eteffects_gmm(df)\n",
    "print(f\"Endogenous treatment-effects estimation    Number of obs = {res.n}\\n\")\n",
    "print(\"Outcome model: linear\\nTreatment model: probit\\n\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"             |               Robust (bootstrap for functionals)\")\n",
    "print(\"   earn98    |  Coefficient   Std. Err.      z     P>|z|\")\n",
    "print(\"-------------+------------------------------------------------\")\n",
    "z = res.ate / res.ate_se_boot\n",
    "from math import erf, sqrt\n",
    "p = 2 * (1 - 0.5 * (1 + erf(abs(z)/sqrt(2))))\n",
    "print(f\"ATE (1 vs 0) | {res.ate:10.5f}   {res.ate_se_boot:9.5f}  {z:6.2f}   {p:0.3f}   [{res.ate_ci[0]:.5f}, {res.ate_ci[1]:.5f}]\")\n",
    "print(\"-------------+------------------------------------------------\")\n",
    "z0 = res.pomean0 / res.pomean0_se_boot\n",
    "p0 = 2 * (1 - 0.5 * (1 + erf(abs(z0)/sqrt(2))))\n",
    "print(f\"POmean 0     | {res.pomean0:10.5f}   {res.pomean0_se_boot:9.5f}  {z0:6.2f}   {p0:0.3f}   [{res.pomean0_ci[0]:.5f}, {res.pomean0_ci[1]:.5f}]\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(\"Convergence:\", res.conv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
