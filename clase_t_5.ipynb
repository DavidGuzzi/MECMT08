{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "279d59d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>black</th>\n",
       "      <th>hisp</th>\n",
       "      <th>married</th>\n",
       "      <th>earn96</th>\n",
       "      <th>unem96</th>\n",
       "      <th>earn98</th>\n",
       "      <th>unem98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.617924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train  age  educ  black  hisp  married  earn96  unem96    earn98  unem98\n",
       "0      0   37    11      1     0        1     0.0       1  1.617924       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyreadstat as st\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 2T\\[MT08-MT13] Microeconometría II\\Clases\\Stata\\jobtraining.dta\"\n",
    "\n",
    "df, meta = st.read_dta(path)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f91e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation  (IPW ATE)\n",
      "\n",
      "Estimator      : inverse-probability weights\n",
      "Outcome model  : weighted mean\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "      earn98 |  Coefficient   Std. Err.         z    P>|z|        [95% Conf. Interval]\n",
      "------------------------------------------------------------------------------\n",
      "         ATE |     1.046882    0.494240     2.118    0.034     (0.078171, 2.015593)\n",
      "    POmean 0 |     9.174996    0.267456    34.305    0.000     (8.650783, 9.699210)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# ---------- Utilidades ----------\n",
    "def _bootstrap(fn, data, n_boot=1000, random_state=123):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    idx = np.arange(len(data))\n",
    "    stats_boot = []\n",
    "    for _ in range(n_boot):\n",
    "        samp = data.iloc[rng.choice(idx, size=len(idx), replace=True)]\n",
    "        stats_boot.append(fn(samp))\n",
    "    return np.array(stats_boot)\n",
    "\n",
    "def _ipw_stats(df, p_col=\"p_hat\", y_col=\"earn98\", d_col=\"train\"):\n",
    "    p = df[p_col].to_numpy()\n",
    "    y = df[y_col].to_numpy()\n",
    "    d = df[d_col].to_numpy()\n",
    "\n",
    "    # Pesos estabilizados y normalizados\n",
    "    w1 = d / p\n",
    "    w0 = (1 - d) / (1 - p)\n",
    "    w1 /= w1.sum()\n",
    "    w0 /= w0.sum()\n",
    "\n",
    "    mu1 = np.sum(w1 * y)\n",
    "    mu0 = np.sum(w0 * y)\n",
    "    ate = mu1 - mu0\n",
    "    return pd.Series({\"mu1\": mu1, \"mu0\": mu0, \"ate\": ate})\n",
    "\n",
    "# ---------- Estimación principal ----------\n",
    "def teffects_ipw(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=[\"age\", \"educ\", \"earn96\"],\n",
    "    noconstant=True,\n",
    "    clip=(1e-6, 1 - 1e-6),\n",
    "    n_boot=2000,\n",
    "    random_state=42\n",
    "):\n",
    "    # 1) Tratamiento ~ X (logit)\n",
    "    X = df[x].copy()\n",
    "    if not noconstant:\n",
    "        X = sm.add_constant(X, has_constant=\"add\")\n",
    "\n",
    "    model = sm.Logit(df[d], X)\n",
    "    res = model.fit(disp=False)\n",
    "\n",
    "    # 2) Propensión y clipping\n",
    "    p_hat = res.predict(X)\n",
    "    if clip is not None:\n",
    "        low, high = clip\n",
    "        p_hat = np.clip(p_hat, low, high)\n",
    "\n",
    "    tmp = df[[y, d]].copy()\n",
    "    tmp[\"p_hat\"] = p_hat\n",
    "\n",
    "    # 3) Estadísticos puntuales\n",
    "    point = _ipw_stats(tmp, p_col=\"p_hat\", y_col=y, d_col=d)\n",
    "\n",
    "    # 4) Bootstrap (no-paramétrico) para SE, z, p, CI\n",
    "    def stat_fn(sample_df):\n",
    "        # Re-estimar p(X) dentro del bootstrap (como hace Stata con \"robust\"?)\n",
    "        Xb = sample_df[x].copy()\n",
    "        if not noconstant:\n",
    "            Xb = sm.add_constant(Xb, has_constant=\"add\")\n",
    "        m_b = sm.Logit(sample_df[d], Xb).fit(disp=False)\n",
    "        p_b = np.clip(m_b.predict(Xb), clip[0], clip[1]) if clip else m_b.predict(Xb)\n",
    "\n",
    "        df_b = sample_df[[y, d]].copy()\n",
    "        df_b[\"p_hat\"] = p_b\n",
    "        s = _ipw_stats(df_b, p_col=\"p_hat\", y_col=y, d_col=d)\n",
    "        # Devolvemos mu0 y ate (para emular POmean train=0 y ATE)\n",
    "        return np.array([s[\"mu0\"], s[\"ate\"]])\n",
    "\n",
    "    boots = _bootstrap(stat_fn, df, n_boot=n_boot, random_state=random_state)\n",
    "    mu0_boot = boots[:, 0]\n",
    "    ate_boot = boots[:, 1]\n",
    "\n",
    "    # SE y z para ATE\n",
    "    ate_se = ate_boot.std(ddof=1)\n",
    "    ate_z = point[\"ate\"] / ate_se if ate_se > 0 else np.nan\n",
    "    ate_p = 2 * (1 - stats.norm.cdf(abs(ate_z)))\n",
    "    ate_ci = (point[\"ate\"] - 1.96 * ate_se, point[\"ate\"] + 1.96 * ate_se)\n",
    "\n",
    "    # SE y z para POmean (train=0)\n",
    "    mu0_se = mu0_boot.std(ddof=1)\n",
    "    mu0_z = point[\"mu0\"] / mu0_se if mu0_se > 0 else np.nan\n",
    "    mu0_p = 2 * (1 - stats.norm.cdf(abs(mu0_z)))\n",
    "    mu0_ci = (point[\"mu0\"] - 1.96 * mu0_se, point[\"mu0\"] + 1.96 * mu0_se)\n",
    "\n",
    "    out = {\n",
    "        \"ATE\": {\n",
    "            \"coef\": float(point[\"ate\"]),\n",
    "            \"se\": float(ate_se),\n",
    "            \"z\": float(ate_z),\n",
    "            \"p\": float(ate_p),\n",
    "            \"ci95\": ate_ci\n",
    "        },\n",
    "        \"POmean_train_0\": {\n",
    "            \"coef\": float(point[\"mu0\"]),\n",
    "            \"se\": float(mu0_se),\n",
    "            \"z\": float(mu0_z),\n",
    "            \"p\": float(mu0_p),\n",
    "            \"ci95\": mu0_ci\n",
    "        },\n",
    "        \"treatment_model\": {\n",
    "            \"params\": res.params.to_dict(),\n",
    "            \"converged\": bool(res.mle_retvals.get(\"converged\", True)),\n",
    "            \"noconstant\": bool(noconstant)\n",
    "        }\n",
    "    }\n",
    "    return out\n",
    "\n",
    "# ---------- Ejecución: ajusta la ruta a tu archivo ----------\n",
    "# Ruta del .dta (cámbiala por la tuya)\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 2T\\[MT08-MT13] Microeconometría II\\Clases\\Stata\\jobtraining.dta\"\n",
    "\n",
    "df = pd.read_stata(path)\n",
    "\n",
    "# Filtros/limpieza opcional: asegurar binaria train y sin NA en variables usadas\n",
    "df = df.dropna(subset=[\"earn98\", \"train\", \"age\", \"educ\", \"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "\n",
    "res = teffects_ipw(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=[\"age\", \"educ\", \"earn96\"],\n",
    "    noconstant=True,      # <- replica \", noconstant\" de Stata\n",
    "    clip=(1e-6, 1 - 1e-6),\n",
    "    n_boot=2000,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(\"Treatment-effects estimation  (IPW ATE)\\n\")\n",
    "print(\"Estimator      : inverse-probability weights\")\n",
    "print(\"Outcome model  : weighted mean\")\n",
    "print(\"Treatment model: logit\")\n",
    "print(\"-\" * 78)\n",
    "print(f\"{'earn98':>12} | {'Coefficient':>12}  {'Std. Err.':>10}  {'z':>8}  {'P>|z|':>7}     {'[95% Conf. Interval]':>23}\")\n",
    "print(\"-\" * 78)\n",
    "ate = res[\"ATE\"]\n",
    "print(f\"{'ATE':>12} | {ate['coef']:12.6f}  {ate['se']:10.6f}  {ate['z']:8.3f}  {ate['p']:7.3f}     ({ate['ci95'][0]:.6f}, {ate['ci95'][1]:.6f})\")\n",
    "mu0 = res[\"POmean_train_0\"]\n",
    "print(f\"{'POmean 0':>12} | {mu0['coef']:12.6f}  {mu0['se']:10.6f}  {mu0['z']:8.3f}  {mu0['p']:7.3f}     ({mu0['ci95'][0]:.6f}, {mu0['ci95'][1]:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1a18a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation  (IPW ATE)\n",
      "\n",
      "Estimator      : inverse-probability weights\n",
      "Outcome model  : weighted mean\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "      earn98 |  Coefficient   Std. Err.         z    P>|z|           [95% Conf. Interval]\n",
      "------------------------------------------------------------------------------\n",
      "         ATE |     1.046882    0.482386     2.170    0.030     (0.101406, 1.992358)\n",
      "    POmean 0 |     9.174996    0.274338    33.444    0.000     (8.637293, 9.712700)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# ---------- IPW con pesos normalizados ----------\n",
    "def _ipw_group_means(y, d, p):\n",
    "    # Pesos no estabilizados (ATE) y normalización por grupo\n",
    "    w1 = d / p\n",
    "    w0 = (1 - d) / (1 - p)\n",
    "    w1 = w1 / w1.sum()\n",
    "    w0 = w0 / w0.sum()\n",
    "    mu1 = np.sum(w1 * y)\n",
    "    mu0 = np.sum(w0 * y)\n",
    "    return mu1, mu0, mu1 - mu0\n",
    "\n",
    "def _fit_logit(df, d, x, noconstant=True):\n",
    "    X = df[x].copy()\n",
    "    if not noconstant:\n",
    "        X = sm.add_constant(X, has_constant=\"add\")\n",
    "    res = sm.Logit(df[d].values, X.values).fit(disp=False)\n",
    "    p = res.predict(X.values)\n",
    "    return res, p\n",
    "\n",
    "def teffects_ipw_python(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=(\"age\", \"educ\", \"earn96\"),\n",
    "    noconstant=True,\n",
    "    clip=(1e-6, 1 - 1e-6),\n",
    "    var_method=\"bootstrap\",   # \"bootstrap\" o \"none\"\n",
    "    n_boot=2000,\n",
    "    random_state=123\n",
    "):\n",
    "    # Ajuste del modelo de tratamiento\n",
    "    res, p = _fit_logit(df, d, x, noconstant=noconstant)\n",
    "    if clip is not None:\n",
    "        p = np.clip(p, clip[0], clip[1])\n",
    "\n",
    "    yv = df[y].to_numpy(dtype=float)\n",
    "    dv = df[d].to_numpy(dtype=float)\n",
    "\n",
    "    mu1, mu0, ate = _ipw_group_means(yv, dv, p)\n",
    "\n",
    "    # Varianza/SE\n",
    "    if var_method == \"bootstrap\":\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        n = len(df)\n",
    "        ate_b = np.empty(n_boot)\n",
    "        mu0_b = np.empty(n_boot)\n",
    "        idx = np.arange(n)\n",
    "\n",
    "        for b in range(n_boot):\n",
    "            ii = rng.choice(idx, size=n, replace=True)\n",
    "            df_b = df.iloc[ii]\n",
    "\n",
    "            res_b, p_b = _fit_logit(df_b, d, x, noconstant=noconstant)\n",
    "            if clip is not None:\n",
    "                p_b = np.clip(p_b, clip[0], clip[1])\n",
    "\n",
    "            yb = df_b[y].to_numpy(dtype=float)\n",
    "            db = df_b[d].to_numpy(dtype=float)\n",
    "\n",
    "            mu1_b, mu0_b[b], ate_b[b] = _ipw_group_means(yb, db, p_b)\n",
    "\n",
    "        ate_se = ate_b.std(ddof=1)\n",
    "        mu0_se = mu0_b.std(ddof=1)\n",
    "    else:\n",
    "        # Sin varianza (placeholder); podés implementar aquí una sándwich IF-based si querés calc analítico.\n",
    "        ate_se = np.nan\n",
    "        mu0_se = np.nan\n",
    "\n",
    "    # Estadísticos\n",
    "    def zpa(ci_est, se):\n",
    "        if not np.isfinite(se) or se == 0:\n",
    "            return np.nan, np.nan, (np.nan, np.nan)\n",
    "        z = ci_est / se\n",
    "        pval = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        ci = (ci_est - 1.96 * se, ci_est + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    ate_z, ate_p, ate_ci = zpa(ate, ate_se)\n",
    "    mu0_z, mu0_p, mu0_ci = zpa(mu0, mu0_se)\n",
    "\n",
    "    # Salida estilo Stata\n",
    "    print(\"Treatment-effects estimation  (IPW ATE)\\n\")\n",
    "    print(\"Estimator      : inverse-probability weights\")\n",
    "    print(\"Outcome model  : weighted mean\")\n",
    "    print(\"Treatment model: logit\")\n",
    "    print(\"-\" * 78)\n",
    "    print(f\"{y:>12} |  {'Coefficient':>11}   {'Std. Err.':>9}  {'z':>8}  {'P>|z|':>7}        {'[95% Conf. Interval]':>23}\")\n",
    "    print(\"-\" * 78)\n",
    "    print(f\"{'ATE':>12} |  {ate:11.6f}   {ate_se:9.6f}  {ate_z:8.3f}  {ate_p:7.3f}     ({ate_ci[0]:.6f}, {ate_ci[1]:.6f})\")\n",
    "    print(f\"{'POmean 0':>12} |  {mu0:11.6f}   {mu0_se:9.6f}  {mu0_z:8.3f}  {mu0_p:7.3f}     ({mu0_ci[0]:.6f}, {mu0_ci[1]:.6f})\")\n",
    "\n",
    "    return {\n",
    "        \"ATE\": dict(coef=ate, se=ate_se, z=ate_z, p=ate_p, ci95=ate_ci),\n",
    "        \"POmean_train_0\": dict(coef=mu0, se=mu0_se, z=mu0_z, p=mu0_p, ci95=mu0_ci),\n",
    "        \"treatment_model\": dict(params=dict(zip(['const']*(not noconstant)+list(x), res.params)),\n",
    "                                converged=bool(res.mle_retvals.get(\"converged\", True)),\n",
    "                                noconstant=bool(noconstant))\n",
    "    }\n",
    "\n",
    "# --------- Ejemplo de uso ----------\n",
    "\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "_ = teffects_ipw_python(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=[\"age\", \"educ\", \"earn96\"],   # <--- lista, no tupla\n",
    "    noconstant=True,\n",
    "    var_method=\"bootstrap\",\n",
    "    n_boot=5000,\n",
    "    random_state=2025\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5915f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation  (IPW ATE)\n",
      "\n",
      "Estimator      : inverse-probability weights\n",
      "Outcome model  : weighted mean\n",
      "Treatment model: logit\n",
      "----------------------------------------------------------------------------------\n",
      "      earn98 |  Coefficient   Std. Err.         z    P>|z|              [95% Conf. Interval]\n",
      "----------------------------------------------------------------------------------\n",
      "         ATE |     1.046882    0.267204     3.918    0.000     (0.523163, 1.570602)\n",
      "    POmean 0 |     9.174996    0.130275    70.428    0.000     (8.919657, 9.430336)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "def _logit_fit_pscore(df, d, x, noconstant=True):\n",
    "    X = df[list(x)].to_numpy(dtype=float)\n",
    "    if not noconstant:\n",
    "        X = sm.add_constant(X, has_constant=\"add\")\n",
    "    y = df[d].to_numpy(dtype=float)\n",
    "    mod = sm.Logit(y, X)\n",
    "    res = mod.fit(disp=False)\n",
    "    p = res.predict(X)\n",
    "    return res, X, y, p\n",
    "\n",
    "def _ipw_normalized_means(y, d, p, clip=None):\n",
    "    if clip is not None:\n",
    "        p = np.clip(p, clip[0], clip[1])\n",
    "\n",
    "    a = d / p\n",
    "    b = (1 - d) / (1 - p)\n",
    "    S1 = a.sum()\n",
    "    S0 = b.sum()\n",
    "    w1 = a / S1\n",
    "    w0 = b / S0\n",
    "\n",
    "    mu1 = np.sum(w1 * y)\n",
    "    mu0 = np.sum(w0 * y)\n",
    "    ate = mu1 - mu0\n",
    "    return mu1, mu0, ate, (w1, w0, S1, S0)\n",
    "\n",
    "def _if_beta_per_obs(X, d, p):\n",
    "    \"\"\"\n",
    "    Influence function de beta (logit MLE):\n",
    "      IF_i(beta) = J^{-1} s_i,  con s_i = x_i (d_i - p_i),\n",
    "      J = (1/n) X' W X, W = diag(p_i (1-p_i))\n",
    "    Devuelve matriz n x k con cada fila IF_i(beta).\n",
    "    \"\"\"\n",
    "    n, k = X.shape\n",
    "    w = p * (1 - p)\n",
    "    WX = X * w[:, None]\n",
    "    J = (X.T @ WX) / n\n",
    "    J_inv = np.linalg.inv(J)\n",
    "    scores = X * (d - p)[:, None]  # n x k\n",
    "    IF_beta = scores @ J_inv.T      # n x k\n",
    "    return IF_beta  # n x k\n",
    "\n",
    "def _grad_mu_normalized_beta(X, y, d, p, mu, group=\"treat1\"):\n",
    "    \"\"\"\n",
    "    Gradiente d mu_g / d beta para IPW normalizado.\n",
    "      Para g=1: a_i = d_i/p_i,  ∂a_i/∂β = - d_i * (1-p_i)/p_i * x_i\n",
    "      Para g=0: b_i = (1-d_i)/(1-p_i), ∂b_i/∂β = (1-d_i) * p_i/(1-p_i) * x_i\n",
    "      d mu_g / dβ = (1/Sg) sum_i ( ∂w_i/∂β * y_i ), con w_i = a_i/S1 o b_i/S0\n",
    "                   = (1/Sg) sum_i [ ∂a_i/∂β (y_i - mu_g) ]  (o análogo para b_i)\n",
    "    Retorna vector k.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    d = np.asarray(d)\n",
    "    p = np.asarray(p)\n",
    "    n, k = X.shape\n",
    "\n",
    "    if group == \"treat1\":\n",
    "        # g=1\n",
    "        # a_i = d/p\n",
    "        S = np.sum(d / p)\n",
    "        # ∂a_i/∂β = - d_i*(1-p_i)/p_i * x_i\n",
    "        coef = - d * (1 - p) / p\n",
    "        resid = (y - mu)  # n,\n",
    "        # sum_i ∂a_i/∂β * (y_i - mu) = sum_i [ coef_i * resid_i * x_i ]\n",
    "        term = (coef * resid)[:, None] * X\n",
    "        grad = term.sum(axis=0) / S\n",
    "        return grad  # k,\n",
    "    else:\n",
    "        # g=0\n",
    "        # b_i = (1-d)/(1-p)\n",
    "        S = np.sum((1 - d) / (1 - p))\n",
    "        # ∂b_i/∂β = (1-d_i) * p_i/(1-p_i) * x_i\n",
    "        coef = (1 - d) * p / (1 - p)\n",
    "        resid = (y - mu)\n",
    "        term = (coef * resid)[:, None] * X\n",
    "        grad = term.sum(axis=0) / S\n",
    "        return grad  # k,\n",
    "\n",
    "def _sandwich_se_ipw_normalized(X, y, d, p, clip=None):\n",
    "    \"\"\"\n",
    "    Calcula SE analíticos sándwich para:\n",
    "      - mu1_hat (IPW normalizado sobre tratados)\n",
    "      - mu0_hat (IPW normalizado sobre no tratados)\n",
    "      - ate_hat  = mu1_hat - mu0_hat\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    if clip is not None:\n",
    "        p = np.clip(p, clip[0], clip[1])\n",
    "\n",
    "    mu1, mu0, ate, (w1, w0, S1, S0) = _ipw_normalized_means(y, d, p, clip=None)\n",
    "\n",
    "    # IF directas (teniendo beta fija):\n",
    "    #   IF_i(mu1) = w1_i * (y_i - mu1)\n",
    "    #   IF_i(mu0) = w0_i * (y_i - mu0)\n",
    "    IF_mu1_direct = w1 * (y - mu1)\n",
    "    IF_mu0_direct = w0 * (y - mu0)\n",
    "    IF_ate_direct = IF_mu1_direct - IF_mu0_direct\n",
    "\n",
    "    # Influence de beta:\n",
    "    IF_beta = _if_beta_per_obs(X, d, p)  # n x k\n",
    "\n",
    "    # Gradientes d mu_g / d beta\n",
    "    g1 = _grad_mu_normalized_beta(X, y, d, p, mu1, group=\"treat1\")  # k,\n",
    "    g0 = _grad_mu_normalized_beta(X, y, d, p, mu0, group=\"treat0\")  # k,\n",
    "    gA = g1 - g0\n",
    "\n",
    "    # Termino indirecto via beta: (∂mu/∂β)' IF_i(β)\n",
    "    IF_mu1 = IF_mu1_direct + IF_beta @ g1\n",
    "    IF_mu0 = IF_mu0_direct + IF_beta @ g0\n",
    "    IF_ate = IF_ate_direct + IF_beta @ gA\n",
    "\n",
    "    # Varianzas asintóticas: Var(theta_hat) ≈ Var(IF)/n\n",
    "    def _se(IF):\n",
    "        IFc = IF - IF.mean()   # centrar por seguridad\n",
    "        var = (IFc @ IFc) / n  # promedio de cuadrados\n",
    "        return np.sqrt(var / n)\n",
    "\n",
    "    se_mu1 = _se(IF_mu1)\n",
    "    se_mu0 = _se(IF_mu0)\n",
    "    se_ate = _se(IF_ate)\n",
    "    return (mu1, se_mu1), (mu0, se_mu0), (ate, se_ate)\n",
    "\n",
    "def teffects_ipw_sandwich(\n",
    "    df,\n",
    "    y=\"earn98\",\n",
    "    d=\"train\",\n",
    "    x=(\"age\", \"educ\", \"earn96\"),\n",
    "    noconstant=True,\n",
    "    clip=(1e-6, 1 - 1e-6),\n",
    "):\n",
    "    # 1) Logit para p(X)\n",
    "    res, X, D, p = _logit_fit_pscore(df, d, x, noconstant=noconstant)\n",
    "    if clip is not None:\n",
    "        p = np.clip(p, clip[0], clip[1])\n",
    "    Y = df[y].to_numpy(dtype=float)\n",
    "\n",
    "    # 2) Puntos y SE analíticos (sándwich) para IPW normalizado\n",
    "    (mu1, se_mu1), (mu0, se_mu0), (ate, se_ate) = _sandwich_se_ipw_normalized(\n",
    "        X, Y, D, p, clip=None\n",
    "    )\n",
    "\n",
    "    # 3) Estadísticos\n",
    "    def zpa(theta, se):\n",
    "        z = theta / se\n",
    "        pval = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        ci = (theta - 1.96 * se, theta + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    z_ate, p_ate, ci_ate = zpa(ate, se_ate)\n",
    "    z_mu0, p_mu0, ci_mu0 = zpa(mu0, se_mu0)\n",
    "\n",
    "    # 4) Salida estilo Stata\n",
    "    print(\"Treatment-effects estimation  (IPW ATE)\\n\")\n",
    "    print(\"Estimator      : inverse-probability weights\")\n",
    "    print(\"Outcome model  : weighted mean\")\n",
    "    print(\"Treatment model: logit\")\n",
    "    print(\"-\" * 82)\n",
    "    header = f\"{y:>12} |  {'Coefficient':>11}   {'Std. Err.':>9}  {'z':>8}  {'P>|z|':>7}           {'[95% Conf. Interval]':>23}\"\n",
    "    print(header)\n",
    "    print(\"-\" * 82)\n",
    "    print(f\"{'ATE':>12} |  {ate:11.6f}   {se_ate:9.6f}  {z_ate:8.3f}  {p_ate:7.3f}     ({ci_ate[0]:.6f}, {ci_ate[1]:.6f})\")\n",
    "    print(f\"{'POmean 0':>12} |  {mu0:11.6f}   {se_mu0:9.6f}  {z_mu0:8.3f}  {p_mu0:7.3f}     ({ci_mu0[0]:.6f}, {ci_mu0[1]:.6f})\")\n",
    "\n",
    "    # (Opcional) podrías imprimir POmean 1 también:\n",
    "    # z_mu1, p_mu1, ci_mu1 = zpa(mu1, se_mu1)\n",
    "    # print(f\"{'POmean 1':>12} |  {mu1:11.6f}   {se_mu1:9.6f}  {z_mu1:8.3f}  {p_mu1:7.3f}     ({ci_mu1[0]:.6f}, {ci_mu1[1]:.6f})\")\n",
    "\n",
    "    return {\n",
    "        \"ATE\": dict(coef=float(ate), se=float(se_ate), z=float(z_ate), p=float(p_ate), ci95=ci_ate),\n",
    "        \"POmean_train_0\": dict(coef=float(mu0), se=float(se_mu0), z=float(z_mu0), p=float(p_mu0), ci95=ci_mu0),\n",
    "        \"POmean_train_1\": dict(coef=float(mu1), se=float(se_mu1)),\n",
    "        \"treatment_model\": dict(params=res.params.tolist(), converged=bool(res.mle_retvals.get(\"converged\", True)), noconstant=bool(noconstant))\n",
    "    }\n",
    "\n",
    "# ---------------- Ejemplo de uso ----------------\n",
    "path = r\"C:\\Users\\HP\\OneDrive\\Escritorio\\David Guzzi\\DiTella\\MEC\\Materias\\2025\\2025 2T\\[MT08-MT13] Microeconometría II\\Clases\\Stata\\jobtraining.dta\"\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "_ = teffects_ipw_sandwich(df, y=\"earn98\", d=\"train\", x=(\"age\",\"educ\",\"earn96\"), noconstant=True, clip=(1e-6, 1-1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9401b9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation                  Number of obs     =       1130\n",
      "Estimator      : augmented IPW\n",
      "Outcome model  : linear by ML\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "             |               Robust\n",
      "       earn98 | Coefficient   std. err.       z   P>|z|     [95% conf. interval]\n",
      "------------------------------------------------------------------------------\n",
      "          ATE |\n",
      "      train |   (1 vs 0)     2.880591    0.430435   6.69  0.000       2.036938      3.724244\n",
      "------------------------------------------------------------------------------\n",
      "       POmean |\n",
      "      train |          0     9.228853    0.263368  35.04  0.000       8.712651      9.745055\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "\n",
    "@dataclass\n",
    "class AIPWResult:\n",
    "    ate: float\n",
    "    ate_se: float\n",
    "    ate_ci: tuple\n",
    "    ate_z: float\n",
    "    ate_p: float\n",
    "    pomean0: float\n",
    "    pomean0_se: float\n",
    "    pomean0_ci: tuple\n",
    "    pomean0_z: float\n",
    "    pomean0_p: float\n",
    "\n",
    "def _add_intercept(X: np.ndarray):\n",
    "    return np.column_stack([np.ones(X.shape[0]), X])\n",
    "\n",
    "def _clip01(p, eps=1e-6):\n",
    "    return np.clip(p, eps, 1-eps)\n",
    "\n",
    "def teffects_aipw(df: pd.DataFrame,\n",
    "                  y_col: str = \"earn98\",\n",
    "                  d_col: str = \"train\",\n",
    "                  x_cols: list = (\"age\", \"educ\", \"earn96\"),\n",
    "                  treatment_noconstant: bool = True) -> AIPWResult:\n",
    "    \"\"\"\n",
    "    Replicates: teffects aipw (Y Xs) (D Xs, noconstant)\n",
    "      - treatment_noconstant=True -> logit without intercept (as in Stata command)\n",
    "      - outcome models are linear (OLS) with intercepts, fit separately by D.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract arrays\n",
    "    Y = df[y_col].astype(float).to_numpy()\n",
    "    D = df[d_col].astype(int).to_numpy()\n",
    "    X = df[list(x_cols)].astype(float).to_numpy()\n",
    "    n = len(Y)\n",
    "\n",
    "    # --- Propensity score model: logit(D ~ X) ---\n",
    "    Xt = X if treatment_noconstant else _add_intercept(X)\n",
    "    logit = sm.Logit(D, Xt).fit(disp=False)\n",
    "    p = _clip01(logit.predict(Xt))\n",
    "\n",
    "    # --- Outcome models: OLS with intercepts, fit separately in treated/controls ---\n",
    "    X1 = _add_intercept(X[D == 1])\n",
    "    X0 = _add_intercept(X[D == 0])\n",
    "    y1 = Y[D == 1]\n",
    "    y0 = Y[D == 0]\n",
    "\n",
    "    ols1 = sm.OLS(y1, X1).fit()\n",
    "    ols0 = sm.OLS(y0, X0).fit()\n",
    "\n",
    "    m1 = ols1.predict(_add_intercept(X))  # m1(X)\n",
    "    m0 = ols0.predict(_add_intercept(X))  # m0(X)\n",
    "\n",
    "    # --- AIPW estimators ---\n",
    "    # ATE EIF for each i:\n",
    "    psi_ate = (m1 - m0) + D * (Y - m1) / p - (1 - D) * (Y - m0) / (1 - p)\n",
    "    ate_hat = psi_ate.mean()\n",
    "    ate_se = psi_ate.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "    # POmean for D=0 (mu0) and its EIF:\n",
    "    # EIF(mu0) = m0(X) + (1-D)*(Y - m0(X))/(1-p) - mu0\n",
    "    phi_mu0 = m0 + (1 - D) * (Y - m0) / (1 - p)\n",
    "    mu0_hat = phi_mu0.mean()\n",
    "    mu0_se = phi_mu0.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "    # Inference\n",
    "    def infer(est, se):\n",
    "        z = est / se\n",
    "        pval = 2 * (1 - norm.cdf(abs(z)))\n",
    "        ci = (est - 1.96 * se, est + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    ate_z, ate_p, ate_ci = infer(ate_hat, ate_se)\n",
    "    mu0_z, mu0_p, mu0_ci = infer(mu0_hat, mu0_se)\n",
    "\n",
    "    return AIPWResult(\n",
    "        ate=ate_hat, ate_se=ate_se, ate_ci=ate_ci, ate_z=ate_z, ate_p=ate_p,\n",
    "        pomean0=mu0_hat, pomean0_se=mu0_se, pomean0_ci=mu0_ci, pomean0_z=mu0_z, pomean0_p=mu0_p\n",
    "    )\n",
    "\n",
    "def print_teffects_table(res: AIPWResult, n_obs: int):\n",
    "    # Format similar to Stata output (rounded sensibly)\n",
    "    def fmt(x): return f\"{x:>10.6f}\"\n",
    "    def fmti(x): return f\"{x:>10.6f}\"\n",
    "    print(\"Treatment-effects estimation\".ljust(46) + f\"Number of obs     = {n_obs:>10}\")\n",
    "    print(\"Estimator      : augmented IPW\")\n",
    "    print(\"Outcome model  : linear by ML\")\n",
    "    print(\"Treatment model: logit\")\n",
    "    print(\"-\" * 78)\n",
    "    print(f\"{'':13}|{'':15}Robust\")\n",
    "    print(f\"{'earn98':>13} | {'Coefficient':>11}  {'std. err.':>10}  {'z':>6}  {'P>|z|':>6}  {'[95% conf. interval]':>23}\")\n",
    "    print(\"-\" * 78)\n",
    "    # ATE row (train: 1 vs 0)\n",
    "    print(f\"{'ATE':>13} |\")\n",
    "    row = [\n",
    "        \"   (1 vs 0) \",\n",
    "        fmt(res.ate), fmt(res.ate_se),\n",
    "        f\"{res.ate_z:6.2f}\", f\"{res.ate_p:6.3f}\",\n",
    "        f\"{fmti(res.ate_ci[0])}    {fmti(res.ate_ci[1])}\"\n",
    "    ]\n",
    "    print(f\"{'train':>11} |{row[0]:>11}{row[1]:>12}{row[2]:>12}{row[3]:>7}{row[4]:>7}     {row[5]}\")\n",
    "    print(\"-\" * 78)\n",
    "    # POmean 0 row\n",
    "    print(f\"{'POmean':>13} |\")\n",
    "    row0 = [\n",
    "        \"          0 \",\n",
    "        fmt(res.pomean0), fmt(res.pomean0_se),\n",
    "        f\"{res.pomean0_z:6.2f}\", f\"{res.pomean0_p:6.3f}\",\n",
    "        f\"{fmti(res.pomean0_ci[0])}    {fmti(res.pomean0_ci[1])}\"\n",
    "    ]\n",
    "    print(f\"{'train':>11} |{row0[0]:>11}{row0[1]:>12}{row0[2]:>12}{row0[3]:>7}{row0[4]:>7}     {row0[5]}\")\n",
    "    print(\"-\" * 78)\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage (adjust df):\n",
    "# df must contain: 'earn98' (Y), 'train' (D in {0,1}), covariates: 'age','educ','earn96'\n",
    "# ---------------------------\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "res = teffects_aipw(df, y_col=\"earn98\", d_col=\"train\",\n",
    "                     x_cols=[\"age\", \"educ\", \"earn96\"],\n",
    "                     treatment_noconstant=True)\n",
    "print_teffects_table(res, n_obs=len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7ad4404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment-effects estimation                  Number of obs     =       1130\n",
      "Estimator      : augmented IPW\n",
      "Outcome model  : linear by ML\n",
      "Treatment model: logit\n",
      "------------------------------------------------------------------------------\n",
      "             |  Robust (bootstrap B=1000)\n",
      "       earn98 | Coefficient   std. err.       z   P>|z|     [95% conf. interval]\n",
      "------------------------------------------------------------------------------\n",
      "          ATE |\n",
      "      train |   (1 vs 0)     2.880591    0.617592   4.66  0.000       1.670112      4.091071\n",
      "------------------------------------------------------------------------------\n",
      "       POmean |\n",
      "      train |          0     9.228853    0.271437  34.00  0.000       8.696836      9.760870\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "\n",
    "# =========================\n",
    "# Núcleo AIPW (plug-in)\n",
    "# =========================\n",
    "@dataclass\n",
    "class AIPWResult:\n",
    "    ate: float\n",
    "    ate_se: float\n",
    "    ate_ci: tuple\n",
    "    ate_z: float\n",
    "    ate_p: float\n",
    "    pomean0: float\n",
    "    pomean0_se: float\n",
    "    pomean0_ci: tuple\n",
    "    pomean0_z: float\n",
    "    pomean0_p: float\n",
    "    B: int = 0\n",
    "    se_source: str = \"influence\"  # \"bootstrap\" cuando usemos Opción 1\n",
    "\n",
    "def _add_intercept(X: np.ndarray):\n",
    "    return np.column_stack([np.ones(X.shape[0]), X])\n",
    "\n",
    "def _clip01(p, eps=1e-6):\n",
    "    return np.clip(p, eps, 1-eps)\n",
    "\n",
    "def teffects_aipw(df: pd.DataFrame,\n",
    "                  y_col: str = \"earn98\",\n",
    "                  d_col: str = \"train\",\n",
    "                  x_cols: list = (\"age\", \"educ\", \"earn96\"),\n",
    "                  treatment_noconstant: bool = True) -> AIPWResult:\n",
    "    \"\"\"\n",
    "    AIPW para: teffects aipw (Y Xs) (D Xs, noconstant)\n",
    "    - logit(D ~ X) sin constante si treatment_noconstant=True\n",
    "    - OLS por separado con intercepto para Y|D=1 y Y|D=0\n",
    "    - Devuelve ATE y POmean (train=0) con SE plug-in (influence simple)\n",
    "    \"\"\"\n",
    "    Y = df[y_col].astype(float).to_numpy()\n",
    "    D = df[d_col].astype(int).to_numpy()\n",
    "    X = df[list(x_cols)].astype(float).to_numpy()\n",
    "    n = len(Y)\n",
    "\n",
    "    # Propensity: logit(D ~ X)\n",
    "    Xt = X if treatment_noconstant else _add_intercept(X)\n",
    "    logit = sm.Logit(D, Xt).fit(disp=False)\n",
    "    p = _clip01(logit.predict(Xt))\n",
    "\n",
    "    # Outcome models con intercepto\n",
    "    X1 = _add_intercept(X[D == 1])\n",
    "    X0 = _add_intercept(X[D == 0])\n",
    "    y1 = Y[D == 1]\n",
    "    y0 = Y[D == 0]\n",
    "\n",
    "    ols1 = sm.OLS(y1, X1).fit()\n",
    "    ols0 = sm.OLS(y0, X0).fit()\n",
    "\n",
    "    m1 = ols1.predict(_add_intercept(X))\n",
    "    m0 = ols0.predict(_add_intercept(X))\n",
    "\n",
    "    # EIFs y estimaciones\n",
    "    psi_ate = (m1 - m0) + D * (Y - m1) / p - (1 - D) * (Y - m0) / (1 - p)\n",
    "    ate_hat = psi_ate.mean()\n",
    "    ate_se = psi_ate.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "    phi_mu0 = m0 + (1 - D) * (Y - m0) / (1 - p)\n",
    "    mu0_hat = phi_mu0.mean()\n",
    "    mu0_se = phi_mu0.std(ddof=1) / np.sqrt(n)\n",
    "\n",
    "    def infer(est, se):\n",
    "        z = est / se\n",
    "        pval = 2 * (1 - norm.cdf(abs(z)))\n",
    "        ci = (est - 1.96 * se, est + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    ate_z, ate_p, ate_ci = infer(ate_hat, ate_se)\n",
    "    mu0_z, mu0_p, mu0_ci = infer(mu0_hat, mu0_se)\n",
    "\n",
    "    return AIPWResult(\n",
    "        ate=ate_hat, ate_se=ate_se, ate_ci=ate_ci, ate_z=ate_z, ate_p=ate_p,\n",
    "        pomean0=mu0_hat, pomean0_se=mu0_se, pomean0_ci=mu0_ci, pomean0_z=mu0_z, pomean0_p=mu0_p\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Opción 1: Bootstrap SEs\n",
    "# =========================\n",
    "def _aipw_point_estimates(df, y_col, d_col, x_cols, treatment_noconstant):\n",
    "    \"\"\"Devuelve (ATE, POmean0) para una muestra dada, re-ajustando todo.\"\"\"\n",
    "    Y = df[y_col].astype(float).to_numpy()\n",
    "    D = df[d_col].astype(int).to_numpy()\n",
    "    X = df[list(x_cols)].astype(float).to_numpy()\n",
    "\n",
    "    Xt = X if treatment_noconstant else np.column_stack([np.ones(X.shape[0]), X])\n",
    "    p = _clip01(sm.Logit(D, Xt).fit(disp=False).predict(Xt))\n",
    "\n",
    "    X1 = _add_intercept(X[D == 1]); y1 = Y[D == 1]\n",
    "    X0 = _add_intercept(X[D == 0]); y0 = Y[D == 0]\n",
    "    ols1 = sm.OLS(y1, X1).fit(); ols0 = sm.OLS(y0, X0).fit()\n",
    "\n",
    "    m1 = ols1.predict(_add_intercept(X))\n",
    "    m0 = ols0.predict(_add_intercept(X))\n",
    "\n",
    "    ate = np.mean((m1 - m0) + D*(Y - m1)/p - (1 - D)*(Y - m0)/(1 - p))\n",
    "    mu0 = np.mean(m0 + (1 - D)*(Y - m0)/(1 - p))\n",
    "    return ate, mu0\n",
    "\n",
    "def teffects_aipw_bootstrap(df: pd.DataFrame,\n",
    "                            y_col: str = \"earn98\",\n",
    "                            d_col: str = \"train\",\n",
    "                            x_cols: list = (\"age\", \"educ\", \"earn96\"),\n",
    "                            treatment_noconstant: bool = True,\n",
    "                            B: int = 500,\n",
    "                            seed: int = 123) -> AIPWResult:\n",
    "    \"\"\"\n",
    "    Calcula SEs por bootstrap para ATE y POmean0.\n",
    "    - Re-muestrea filas con reemplazo y re-ajusta logit + OLS en cada réplica.\n",
    "    - Devuelve las mismas métricas (z, p, CI) usando SE_bootstrap (normal-approx).\n",
    "    \"\"\"\n",
    "    # Estimación puntual en muestra completa\n",
    "    base_res = teffects_aipw(df, y_col, d_col, x_cols, treatment_noconstant)\n",
    "    ate_hat, mu0_hat = base_res.ate, base_res.pomean0\n",
    "\n",
    "    # Bootstrap\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(df)\n",
    "    ate_b = np.empty(B); mu0_b = np.empty(B)\n",
    "\n",
    "    for b in range(B):\n",
    "        idx = rng.integers(low=0, high=n, size=n)\n",
    "        samp = df.iloc[idx].reset_index(drop=True)\n",
    "        ate_b[b], mu0_b[b] = _aipw_point_estimates(\n",
    "            samp, y_col, d_col, x_cols, treatment_noconstant\n",
    "        )\n",
    "\n",
    "    ate_se = ate_b.std(ddof=1)\n",
    "    mu0_se = mu0_b.std(ddof=1)\n",
    "\n",
    "    # Inferencia normal (como Stata reporta en teffects)\n",
    "    def infer(est, se):\n",
    "        z = est / se\n",
    "        pval = 2 * (1 - norm.cdf(abs(z)))\n",
    "        ci = (est - 1.96 * se, est + 1.96 * se)\n",
    "        return z, pval, ci\n",
    "\n",
    "    ate_z, ate_p, ate_ci = infer(ate_hat, ate_se)\n",
    "    mu0_z, mu0_p, mu0_ci = infer(mu0_hat, mu0_se)\n",
    "\n",
    "    return AIPWResult(\n",
    "        ate=ate_hat, ate_se=ate_se, ate_ci=ate_ci, ate_z=ate_z, ate_p=ate_p,\n",
    "        pomean0=mu0_hat, pomean0_se=mu0_se, pomean0_ci=mu0_ci, pomean0_z=mu0_z, pomean0_p=mu0_p,\n",
    "        B=B, se_source=\"bootstrap\"\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Impresión estilo Stata\n",
    "# =========================\n",
    "def print_teffects_table(res: AIPWResult, n_obs: int):\n",
    "    def fmt(x): return f\"{x:>10.6f}\"\n",
    "    def fmti(x): return f\"{x:>10.6f}\"\n",
    "    print(f\"Treatment-effects estimation\".ljust(46) + f\"Number of obs     = {n_obs:>10}\")\n",
    "    print(\"Estimator      : augmented IPW\")\n",
    "    print(\"Outcome model  : linear by ML\")\n",
    "    print(\"Treatment model: logit\")\n",
    "    label = \"Robust (bootstrap B={})\".format(res.B) if res.se_source == \"bootstrap\" else \"Robust\"\n",
    "    print(\"-\" * 78)\n",
    "    print(f\"{'':13}|{label:>27}\")\n",
    "    print(f\"{'earn98':>13} | {'Coefficient':>11}  {'std. err.':>10}  {'z':>6}  {'P>|z|':>6}  {'[95% conf. interval]':>23}\")\n",
    "    print(\"-\" * 78)\n",
    "    # ATE\n",
    "    print(f\"{'ATE':>13} |\")\n",
    "    row = [\n",
    "        \"   (1 vs 0) \",\n",
    "        fmt(res.ate), fmt(res.ate_se),\n",
    "        f\"{res.ate_z:6.2f}\", f\"{res.ate_p:6.3f}\",\n",
    "        f\"{fmti(res.ate_ci[0])}    {fmti(res.ate_ci[1])}\"\n",
    "    ]\n",
    "    print(f\"{'train':>11} |{row[0]:>11}{row[1]:>12}{row[2]:>12}{row[3]:>7}{row[4]:>7}     {row[5]}\")\n",
    "    print(\"-\" * 78)\n",
    "    # POmean 0\n",
    "    print(f\"{'POmean':>13} |\")\n",
    "    row0 = [\n",
    "        \"          0 \",\n",
    "        fmt(res.pomean0), fmt(res.pomean0_se),\n",
    "        f\"{res.pomean0_z:6.2f}\", f\"{res.pomean0_p:6.3f}\",\n",
    "        f\"{fmti(res.pomean0_ci[0])}    {fmti(res.pomean0_ci[1])}\"\n",
    "    ]\n",
    "    print(f\"{'train':>11} |{row0[0]:>11}{row0[1]:>12}{row0[2]:>12}{row0[3]:>7}{row0[4]:>7}     {row0[5]}\")\n",
    "    print(\"-\" * 78)\n",
    "\n",
    "# =========================\n",
    "# Ejemplo de uso\n",
    "# =========================\n",
    "# df: DataFrame con columnas 'earn98' (Y), 'train' (D en {0,1}), 'age','educ','earn96'.\n",
    "df = pd.read_stata(path).dropna(subset=[\"earn98\",\"train\",\"age\",\"educ\",\"earn96\"]).copy()\n",
    "df[\"train\"] = (df[\"train\"] > 0).astype(int)\n",
    "res = teffects_aipw_bootstrap(\n",
    "    df,\n",
    "    y_col=\"earn98\",\n",
    "    d_col=\"train\",\n",
    "    x_cols=[\"age\", \"educ\", \"earn96\"],\n",
    "    treatment_noconstant=True,\n",
    "    B=1000,   # aumentar para mayor precisión\n",
    "    seed=123\n",
    ")\n",
    "print_teffects_table(res, n_obs=len(df))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
